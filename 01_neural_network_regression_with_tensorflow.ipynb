{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_neural_network_regression_with_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMs9warKRS7dgzyKxVKe0/I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aleguma/tf-cert/blob/main/01_neural_network_regression_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression problems...\n",
        "* Predicting a number of some sort (non-formal definition)\n",
        "* Set of statistical processes for estimating the relationship between a dependent variable (outcome variable) and one or more independent variables, which are often called predictors, covariates or features  (a bit more formal)\n",
        "\n",
        "### Examples of Regression problems (i.e., how much/how many sort of predictions):\n",
        "* Predict sell prices of a house?\n",
        "* How many people will buy this app?\n",
        "* How much will my health insurance be?\n",
        "* How much shouldI save each week for fuel?\n",
        "* But also...\n",
        "* Predict the coordinates of where the bounding boxes (box corners coordinates) should be in an object detection problem.\n"
      ],
      "metadata": {
        "id": "20So3es2MwxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Docstring in Colab -> Shift + CMD/Windows + Space."
      ],
      "metadata": {
        "id": "YU7aNZppOdFc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What we are going to cover in this notebook\n",
        "\n",
        "* Architecture of a neural network regression model (building blocs)\n",
        "* Input shapes and output shapes of a regression model (features and labels; independent and dependent variables)\n",
        "* Creating custom data to view and fit\n",
        "* Steps in modelling\n",
        "  * Creating a model, compiling a model, fitting a model, evaluating a model\n",
        "* Different evaluation methods\n",
        "* Saving and loading models"
      ],
      "metadata": {
        "id": "tkSMy58FRPGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regression inputs and outputs\n",
        "\n",
        "* Inputs: data variables used to predict the output (e.g., number of bedrooms, number of bathrooms, house size, etc.). The input features' values are encoded numerically (e.g., real numbers, one-hot encoding)\n",
        "* Outputs: value we are trying to predict, that is, predicted output (e.g., house price). It is based on some actual outputs we already know for some combination of inputs/outputs (i.e., data samples).\n",
        "* We try to learn the relationship of the inputs (independent variables) and outputs (dependent variables) to predict about unknown outputs given specific inputs!. Often a Machine Learning algorithm already exists for your problem (you can maybe utilize it). If it doesn't already exist, you can build your own.\n",
        "* This is an example of supervised learning. We train the model with examples of inputs and outputs we already know. The machine learning algorithm is going to learn the relationship. This relationship can be used later to forecast about unknown outputs for some input feature values. After the ML algorithm has looked at many many examples (a lots of inputs/outputs), learns the relation between the input features and outputs, and then for use cases you do not actually know the output, it is going to be able to predict about it.\n",
        "* Defining inputs and outputs is where much of the work is in Deep Learning. Especially the input and output shapes. All of these are in the form of a tensor. The shape of the input might vary according to the encoding and the number of input features, but usually the shape of the output for a regression problem is 1. The output shape is usually one because we are trying to predict a single number.\n"
      ],
      "metadata": {
        "id": "Emk7pXZ_RZ0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Anatomy and architecture of a neural network regression model\n",
        "\n",
        "Every neural network built will have an input layer, some number of hidden layers and an output layer. Data goes in by the input layer, the hidden layer/s (i.e., 1 or 1000, the more layers, the deeper is the neural net; that is where the deep in deep learning come from) and then the output layer, where the outputs or learned representation or prediction probabilities come out. Within the hidden layers is where the NN learns patterns or weights in the data. \n",
        "\n",
        "With these building blocks, how would the architecture of a regression model looks like?"
      ],
      "metadata": {
        "id": "Q4QNmMkpSxKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Typical architecture of a regression model\n",
        "\n",
        "There will be a few hyperparameters. A hyperparameters is a setting that can be changed and affects the learning/training.\n",
        "\n",
        "* **Input layer shape** = same shape as number of features (e.g., 3 for # bedrooms, # bathrooms, # car spaces in housing price prediction).\n",
        "* **Hidden layer(s)** = problem specific, minimim = 1, maximum = unlimited.\n",
        "* **Neurons per hidden layer** = problem specific, generally 10 to 100.\n",
        "* **Output layer shape** = same shape as desired prediction shape (e.g., 1 for house price).\n",
        "* **Hidden activation** = Usually ReLU (rectified linear unit).\n",
        "* **Output activation** = problem specific. None, ReLU, logistic/tanh.\n",
        "* **Loss function** = MSE (mean square error) or MAE  (mean absolute error)/Huber loss (combination of MAE/MSE) if outliers in the data. (Measures how wrong our NN predictions are, how wrong the neural relationships between input/output are).\n",
        "* **Optimizer** = SGD (stochastic gradient descent), Adam. (Informs the NN about how it should improve the predictions, the patterns that is learning to reduce the loss function, the error).\n",
        "\n",
        "(Adapted from page 293 of Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow by Aurelien Geron)."
      ],
      "metadata": {
        "id": "iE5owyPYa1BP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Regression with Neural Networks in TensorFlow\n",
        "\n",
        "There are many definitions for a regression problem but in our case, we're going to simplify it: predicting a numeric variable based on some other combination of variables, even shorter...predicting a number!"
      ],
      "metadata": {
        "id": "pfCerwuqEn88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow and check version\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKzAqZ-zGAIq",
        "outputId": "6da7cade-d801-48de-8d3c-a1a9a0871d3d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a data to view and fit\n",
        "\n"
      ],
      "metadata": {
        "id": "Y-DB6lEcGbfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])   # independent variable\n",
        "\n",
        "# Create labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])   # dependent variable\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(X, y)  # very simple line scatterplot\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "vC65kVBfGhj2",
        "outputId": "005f875a-4456-4327-adba-f9e356a419df"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f6537ee3ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOP0lEQVR4nO3df2jc933H8ddrigZHGlCCVWNpMR4lHIRBrU6EQctIadfL8o+Vf8LyR/FYwPmjgY6Vg6j/NDAGYdcf/2wUHBriQZtRqKKEUXrNTJkpjDG5MpXT7EgpNsvJsR26oxl8YYr63h/6npFcS/dDd/refe75AKG7z33le/NFeeb8/X7P54gQACAdv1f0AACAwSLsAJAYwg4AiSHsAJAYwg4AiSHsAJCYjmG3/bDtn9j+he23bX85X3/RdtP2lfzryeGPCwDoxJ2uY7d9QtKJiPiZ7QckXZa0JOlpSf8bEV8f/pgAgG7d12mDiLgh6UZ++0Pb70iaH/ZgAID+dHzFvmdj+5SkS5L+SNLfSPpLSb+RtCbpKxHxPwf9/LFjx+LUqVP9TQoAE+ry5csfRMRst9t3HXbbH5P0b5L+LiJWbB+X9IGkkPS32jlc81f3+Llzks5J0smTJ//4+vXr3c4GAJBk+3JELHa7fVdXxdielvQDSd+NiBVJioibEbEdEb+V9LKkx+71sxFxPiIWI2Jxdrbr/+EAAPrUzVUxlvQdSe9ExDd3rZ/YtdlTkq4OfjwAQK86njyV9GlJX5S0YftKvvZVSc/YPq2dQzHXJD03lAkBAD3p5qqYn0ryPR764eDHAQAcFu88BYDEdHMoBgDQp9X1pmr1hjZbmeZmSqpWylpaGO5bgQg7AAzJ6npTyysbyra2JUnNVqbllQ1JGmrcORQDAENSqzfuRL0t29pWrd4Y6vMSdgAYks1W1tP6oBB2ABiSuZlST+uDQtgBYEiqlbJK01N71krTU6pWykN9Xk6eAsCQtE+QclUMACRkaWF+6CG/G4diACAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEsOHWQMYK6vrTdXqDW22Ms3NlFStlI/8w6JHHWEHMDZW15taXtlQtrUtSWq2Mi2vbEgScd+FQzEAxkat3rgT9bZsa1u1eqOgiUYTYQcwNjZbWU/rk4qwAxgbczOlntYnFWEHMDaqlbJK01N71krTU6pWygVNNJo4eQpgbLRPkHJVzMEIO4CxsrQwT8g74FAMACSmY9htP2z7J7Z/Yftt21/O1x+y/Zbtd/PvDw5/XABAJ928Yv9I0lci4lFJfyLpS7YflfSCpIsR8Yiki/l9AEDBOoY9Im5ExM/y2x9KekfSvKQzki7km12QtDSsIQEA3evpGLvtU5IWJP2HpOMRcSN/6H1Jxwc6GQCgL12H3fbHJP1A0l9HxG92PxYRISn2+blzttdsr92+fftQwwIAOusq7LantRP170bESr580/aJ/PETkm7d62cj4nxELEbE4uzs7CBmBgAcoJurYizpO5LeiYhv7nroTUln89tnJb0x+PEAAL3q5g1Kn5b0RUkbtq/ka1+V9JKk79t+VtJ1SU8PZ0QAQC86hj0ifirJ+zz8ucGOAwA4LN55CgCJIewAkBjCDgCJIewAkBjCDgCJIewAkBjCDgCJIewAkBjCDgCJIewAkBjCDgCJ6eYfAQOQuNX1pmr1hjZbmeZmSqpWylpamC96LPSJsAMTbnW9qeWVDWVb25KkZivT8sqGJBH3McWhGGDC1eqNO1Fvy7a2Vas3CpoIh0XYgQm32cp6WsfoI+zAhJubKfW0jtFH2IEJV62UVZqe2rNWmp5StVIuaCIcFidPgQnXPkHKVTHpIOwAtLQwT8gTwqEYAEgMYQeAxBB2AEgMYQeAxBB2AEgMYQeAxBB2AEgMYQeAxBB2AEgMYQeAxBB2AEgMYQeAxBB2AEgMYQeAxBB2AEgMYQeAxBB2AEgMYQeAxBB2AEhMx7DbfsX2LdtXd629aLtp+0r+9eRwxwQAdKubD7N+VdI/SPqnu9a/FRFfH/hEQAJW15uq1RvabGWamympWinzYdE4Mh3DHhGXbJ8a/ihAGlbXm1pe2VC2tS1JarYyLa9sSBJxx5E4zDH2523/PD9U8+DAJgLGXK3euBP1tmxrW7V6o6CJMGn6Dfu3JX1C0mlJNyR9Y78NbZ+zvWZ77fbt230+HTA+NltZT+vAoPUV9oi4GRHbEfFbSS9LeuyAbc9HxGJELM7OzvY7JzA25mZKPa0Dg9ZX2G2f2HX3KUlX99sWmDTVSlml6ak9a6XpKVUr5YImwqTpePLU9muSHpd0zPZ7kr4m6XHbpyWFpGuSnhvijMBYaZ8g5aoYFMURcWRPtri4GGtra0f2fACQAtuXI2Kx2+155ykAJIawA0BiCDsAJIawA0BiCDsAJIawA0BiCDsAJIawA0BiCDsAJIawA0BiCDsAJIawA0BiCDsAJIawA0BiCDsAJIawA0BiCDsAJIawA0BiCDsAJIawA0Bi7it6AKBbq+tN1eoNbbYyzc2UVK2UtbQwX/RYwMgh7BgLq+tNLa9sKNvaliQ1W5mWVzYkibgDd+FQDMZCrd64E/W2bGtbtXqjoImA0UXYMRY2W1lP68AkI+wYC3MzpZ7WgUlG2DEWqpWyStNTe9ZK01OqVsoFTQSMLk6eYiy0T5ByVQzQGWHH2FhamCfkQBc4FAMAiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJCYjmG3/YrtW7av7lp7yPZbtt/Nvz843DEBAN3q5hX7q5KeuGvtBUkXI+IRSRfz+wCAEdAx7BFxSdKv71o+I+lCfvuCpKUBzwUA6FO/x9iPR8SN/Pb7ko4PaB4AwCEd+uRpRISk2O9x2+dsr9leu3379mGfDgDQQb9hv2n7hCTl32/tt2FEnI+IxYhYnJ2d7fPpAADd6jfsb0o6m98+K+mNwYwDADisbi53fE3Sv0sq237P9rOSXpL0Z7bflfT5/D4AYAR0/Gi8iHhmn4c+N+BZAAADwDtPASAxfJj1BFtdb6pWb2izlWlupqRqpcyHRQMJIOwTanW9qeWVDWVb25KkZivT8sqGJBF3YMxxKGZC1eqNO1Fvy7a2Vas3CpoIwKAQ9gm12cp6WgcwPgj7hJqbKfW0DmB8EPYJVa2UVZqe2rNWmp5StVIuaCIAg8LJ0wnVPkHKVTFAegj7BFtamCfkQII4FAMAiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4AiSHsAJAYwg4Aibmv6AFSs7reVK3e0GYr09xMSdVKWUsL80WPBWCCEPYBWl1vanllQ9nWtiSp2cq0vLIhScQdwJHhUMwA1eqNO1Fvy7a2Vas3CpoIwCQi7AO02cp6WgeAYSDsAzQ3U+ppHQCGgbAPULVSVml6as9aaXpK1Uq5oIkATCJOng5Q+wQpV8UAKBJhH7ClhXlCDqBQhwq77WuSPpS0LemjiFgcxFAAgP4N4hX7ZyPigwH8OQCAAeDkKQAk5rBhD0k/tn3Z9rlBDAQAOJzDHor5TEQ0bX9c0lu2/ysiLu3eIA/+OUk6efLkIZ8OANDJoV6xR0Qz/35L0uuSHrvHNucjYjEiFmdnZw/zdACALvQddtv3236gfVvSFyRdHdRgAID+HOZQzHFJr9tu/znfi4gfDWQqAEDf+g57RPxK0icHOAsAYAC43BEAEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEkPYASAxhB0AEjPyH2a9ut5Urd7QZivT3ExJ1UqZD4sGgAOMdNhX15taXtlQtrUtSWq2Mi2vbEgScQeAfYz0oZhavXEn6m3Z1rZq9UZBEwHA6BvpsG+2sp7WAQAjHva5mVJP6wCAEQ97tVJWaXpqz1ppekrVSrmgiQBg9I30ydP2CVKuigGA7o102KWduBNyAOjeSB+KAQD0jrADQGIIOwAkhrADQGIIOwAkxhFxdE9m35Z0/cie8PCOSfqg6CFGHPvoYOyfzthHBzsm6f6ImO32B4407OPG9lpELBY9xyhjHx2M/dMZ++hg/ewfDsUAQGIIOwAkhrAf7HzRA4wB9tHB2D+dsY8O1vP+4Rg7ACSGV+wAkBjC3oHtF203bV/Jv54seqZRYPsJ2w3bv7T9QtHzjCLb12xv5L83a0XPUzTbr9i+ZfvqrrWHbL9l+938+4NFzli0ffZRzw0i7N35VkSczr9+WPQwRbM9JekfJf25pEclPWP70WKnGlmfzX9vuJxPelXSE3etvSDpYkQ8Iulifn+Svarf3UdSjw0i7OjHY5J+GRG/ioj/k/TPks4UPBNGXERckvTru5bPSLqQ374gaelIhxox++yjnhH27jxv++f5X5Mm+q+KuXlJ/73r/nv5GvYKST+2fdn2uaKHGVHHI+JGfvt9SceLHGaE9dQgwi7J9r/avnqPrzOSvi3pE5JOS7oh6RuFDotx8pmI+JR2Dll9yfafFj3QKIudS/S4TO939dygkf8EpaMQEZ/vZjvbL0v6lyGPMw6akh7edf8P8jXsEhHN/Pst269r5xDWpWKnGjk3bZ+IiBu2T0i6VfRAoyYibrZvd9sgXrF3kP+ytT0l6ep+206Q/5T0iO0/tP37kv5C0psFzzRSbN9v+4H2bUlfEL879/KmpLP57bOS3ihwlpHUT4N4xd7Z39s+rZ2/Il6T9Fyx4xQvIj6y/bykuqQpSa9ExNsFjzVqjkt63ba089/Z9yLiR8WOVCzbr0l6XNIx2+9J+pqklyR93/az2vmXX58ubsLi7bOPHu+1QbzzFAASw6EYAEgMYQeAxBB2AEgMYQeAxBB2AEgMYQeAxBB2AEgMYQeAxPw/YhrWmPXy7VoAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The relatio between X and y in the example is y = X + 10\n",
        "y == X + 10    # --> this is the relationship or function that we want our NN to learn!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcv34KIpG9fA",
        "outputId": "c4f69f42-3daf-43cd-8707-fc11bfa7ddca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input and output shapes\n",
        "\n",
        "They vary depending on the problem you are working on."
      ],
      "metadata": {
        "id": "QvXQ1QAJHVPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a demo tensor for our housing price prediction problem\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
        "house_price = tf.constant([937000])\n",
        "\n",
        "house_info, house_price   # sizes are then vector of 3 and scalar\n",
        "# input shape is gonna be 3, and the output shape is gonna be 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8hIlYJ1HoLH",
        "outputId": "a2fb8e91-b9af-400a-94cb-8afe3539f89f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([937000], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In the previous example (scatterplot)\n",
        "input_shape = X.shape\n",
        "output_shape = y.shape\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNjXi4KtIGDh",
        "outputId": "1011d8a9-47f4-4de2-f909-a0ee8c33fdb6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8,), (8,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Is this correct? Not really...as that is the collection of samples (8) \n",
        "# Our samples are composed of 1 input feature and 1 label\n",
        "X[0], y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHTmAfGPIan8",
        "outputId": "a7b360de-c0f6-4c95-85ad-15a5e286eef2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[1], y[1]  # we use X[1] to predict y[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf6JQ_j0IkFy",
        "outputId": "91f12c9f-eee8-485d-bf5f-49cfc09f16a3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-4.0, 6.0)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# So then, the correct shape is...\n",
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xep3TlctIzB1",
        "outputId": "5d802611-e209-4915-e3ea-7498fbb27451"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((), ())"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# So the shape is () as we have special type of tensors, rank-0 tensors, scalars.\n",
        "# So we have scalars as features and scalars as labels/targets.\n",
        "X[0].ndim, y[0].ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvyOUuqhI5uY",
        "outputId": "8ee2c74c-a1e5-4fe7-e4a0-2a770fb5d295"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0], y[0] # we are going to build a model that is going to take as input negative seven and output 3, as in this training example"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n03IicDwJTcO",
        "outputId": "47f67bce-59e4-4f8c-ca54-82d0975deda1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In our model, we will use one X/input value to predict one y/output value."
      ],
      "metadata": {
        "id": "i7eBHdCXJdEU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn out NumPy arrays into tensors (we might need to change the float value sometimes if some error)\n",
        "X = tf.constant(X)  \n",
        "y = tf.constant(y)\n",
        "X, y\n",
        "\n",
        "# we might need sometimes to change data type to avoid some warnings\n",
        "# could be done like...\n",
        "#X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
        "#y = tf.cast(tf.constant(y), dtype=tf.float32)\n",
        "#X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIF8e6xxJlxM",
        "outputId": "dceac299-0578-4e8d-ab7f-30d10cf437d5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape  # When there are no dimensions, means a scalar value, a single value (rank-0 or 0-dimensional tensor!)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9hbXO0yKF-V",
        "outputId": "47b6e3b7-f936-4dbe-c561-f3ef994c1e1d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps in modelling with TensorFlow\n",
        "\n",
        "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
        "2. **Compile a model** - define the loss function (in other words, the function which tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of our model).\n",
        "3. **Fitting a model** - letting the model try to find patterns between X and y (features and labels)."
      ],
      "metadata": {
        "id": "IXQCoMtuKLo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A bit more of an in-depth guide to modelling with TensorFlow\n",
        "\n",
        "1. Construct or import a pretrained model relevant to your problem\n",
        "2. Compile the model (prepare it to be used with data)\n",
        "  * Loss - how wrong your model's predictions are compared to the truth labels (you want to minimize this).\n",
        "  * Optimizer - how your model should update its internal patterns to better its predictions.\n",
        "  * Metrics - human interpretable values for how well your model is doing.\n",
        "3. Fit the model to the training data so it can discover patterns.\n",
        "  * Epochs - how many times the model will go through all of the training examples.\n",
        "4. Evaluate the model on the test data (how reliable are our model's predictions?)"
      ],
      "metadata": {
        "id": "woBseWHQUN1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API\n",
        "# In Keras you can create models using the Sequential or the Functional API\n",
        "# Using the Sequential you can do it adding the stack of layers as a list....\n",
        "model = tf.keras.Sequential([    # it says, create model that sequentially goes through the following layers\n",
        "    tf.keras.layers.Dense(1)   # we predict a number with another number, so that is it\n",
        "])\n",
        "\n",
        "# Or it could also be defined as...(adding to the object Sequential object with the add method)\n",
        "# model = tf.keras.Sequential()\n",
        "# model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, #MAE is short for mean absolute error; comparisons of predicted vs. observed output. It says, on average, how wrong are our predictions?\n",
        "              optimizer=tf.keras.optimizers.SGD(), #SGD is short for Stochastic Gradient Descent, tells the network how it should improve!\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)  # It says look to X and y and try to figure out the patterns by going 5 times through the whole training set (set of examples)\n",
        "# An epoch is a the usage of the whole training set once. So this is looking or using the whole training set 5 times, going over through it five times to try to find the patterns, relationship between X and y."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_sLVvVHLDTG",
        "outputId": "5dec2e3c-5a00-4f72-deb8-a978755cc8be"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.9748 - mae: 10.9748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6596f67fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out X and y\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37nCI_KpQWy4",
        "outputId": "265a42b8-7848-42c7-d411-abb97631b4f3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try and make a prediction using our model\n",
        "y_pred = model.predict([17.0])  # should be 27!\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOEeNtRrQaQR",
        "outputId": "5d035622-c801-4a95-fb18-bb78c446b3de"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.716021]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred + 11 # how much on average is off according to mae metric, still far off!\n",
        "# It fails, as it indicated by the loss and performance metric. How our model is wrong on average.\n",
        "# So our trained model did not find the correct patterns between X and y. So let's improve it!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wcGKswSQfG2",
        "outputId": "56a8f5ef-3613-404e-f2e9-490a5aee8642"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23.71602]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving our model\n",
        "\n",
        "We can improve our model by altering the steps we took to create a model. Briefly...\n",
        "\n",
        "1. **Creating a model** - here we might add more layers, increase the number of hidden units (also called neurons) within each of the hidden layers, and we might change the activation functions of each layer.\n",
        "2. **Compiling a model** - here we might change the optimization function or perhaps the *learning rate* of the optimization function.\n",
        "3. **Fitting a model** - here we might fit a model for more epochs (let it look at the training data more times, leave it training for longer) or on more data (give the model more examples to learn from)."
      ],
      "metadata": {
        "id": "F7kNlNaNRB2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPROVING THE PREVIOUS MODEL PERFORMANCE\n",
        "\n",
        "# Improve one, increasing the number of epochs\n",
        "\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([    \n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(), \n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model (this time we'll train for longer)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)  # just increasing the epochs, the loss and mae went down almost half!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8xpaB9RSaPl",
        "outputId": "57c2e122-2934-41f5-8b46-326a0361d971"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.9748 - mae: 10.9748\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.8423 - mae: 10.8423\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.7098 - mae: 10.7098\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.5773 - mae: 10.5773\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.4448 - mae: 10.4448\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.3123 - mae: 10.3123\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.1798 - mae: 10.1798\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.0473 - mae: 10.0473\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.9148 - mae: 9.9148\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 9.7823 - mae: 9.7823\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.6498 - mae: 9.6498\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 9.5173 - mae: 9.5173\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.3848 - mae: 9.3848\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.2523 - mae: 9.2523\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.1198 - mae: 9.1198\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.9873 - mae: 8.9873\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.8548 - mae: 8.8548\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.7223 - mae: 8.7223\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.5898 - mae: 8.5898\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4573 - mae: 8.4573\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3248 - mae: 8.3248\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.1923 - mae: 8.1923\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.0598 - mae: 8.0598\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.9273 - mae: 7.9273\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.7948 - mae: 7.7948\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.6623 - mae: 7.6623\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.5298 - mae: 7.5298\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.3973 - mae: 7.3973\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2648 - mae: 7.2648\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2413 - mae: 7.2413\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1963 - mae: 7.1963\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1738 - mae: 7.1738\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1063 - mae: 7.1063\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8869 - mae: 6.8869\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8813 - mae: 6.8813\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f65322f5290>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remind ourselves of the data\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbQJCJqoU7kL",
        "outputId": "d960fd60-c953-4be6-dda5-0f03290b0837"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if our model's prediction has improved...\n",
        "model.predict([17.0]) # much better prediction just tweaking one hyperparameter of our smaller model!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGdQE6zyY8dY",
        "outputId": "8b054f17-a1f4-4945-ff02-50acb46b0dc3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[30.158512]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPROVING THE PREVIOUS MODEL PERFORMANCE\n",
        "\n",
        "# Tweaking another hyperparameter, changing the optimizer and the learning rate\n",
        "\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([    \n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), # larger the learning rate, larger the steps the optimizer tells the NN to improve the learnin!\n",
        "              metrics=[\"mae\"])                                          # smaller steps, correspond to lower learning rate                  \n",
        "\n",
        "# 3. Fit the model (this time we'll train for longer)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lMJyHctZEcO",
        "outputId": "877f34e5-c841-4c7f-b0d1-f353c036befd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.0548 - mae: 11.0548\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.6048 - mae: 10.6048\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.1548 - mae: 10.1548\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 9.7048 - mae: 9.7048\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.2548 - mae: 9.2548\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 8.8048 - mae: 8.8048\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3548 - mae: 8.3548\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.9048 - mae: 7.9048\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.4548 - mae: 7.4548\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0048 - mae: 7.0048\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6750 - mae: 6.6750\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6013 - mae: 6.6013\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6652 - mae: 6.6652\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7835 - mae: 6.7835\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8536 - mae: 6.8536\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8819 - mae: 6.8819\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8739 - mae: 6.8739\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8341 - mae: 6.8341\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.7664 - mae: 6.7664\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.6741 - mae: 6.6741\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.5602 - mae: 6.5602\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.4269 - mae: 6.4269\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.2766 - mae: 6.2766\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 6.1110 - mae: 6.1110\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 5.9319 - mae: 5.9319\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.7406 - mae: 5.7406\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.6637 - mae: 5.6637\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.6047 - mae: 5.6047\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5441 - mae: 5.5441\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5875 - mae: 5.5875\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5963 - mae: 5.5963\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5469 - mae: 5.5469\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4464 - mae: 5.4464\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.3007 - mae: 5.3007\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.1335 - mae: 5.1335\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.0600 - mae: 5.0600\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.9867 - mae: 4.9867\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.9135 - mae: 4.9135\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.8405 - mae: 4.8405\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.7975 - mae: 4.7975\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.7608 - mae: 4.7608\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.6963 - mae: 4.6963\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.6069 - mae: 4.6069\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4952 - mae: 4.4952\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.4298 - mae: 4.4298\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.3643 - mae: 4.3643\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.2979 - mae: 4.2979\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.2308 - mae: 4.2308\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1630 - mae: 4.1630\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 4.0946 - mae: 4.0946\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 4.0652 - mae: 4.0652\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9794 - mae: 3.9794\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.8806 - mae: 3.8806\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.8071 - mae: 3.8071\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.7336 - mae: 3.7336\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.6601 - mae: 3.6601\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5867 - mae: 3.5867\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5133 - mae: 3.5133\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4709 - mae: 3.4709\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4081 - mae: 3.4081\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3176 - mae: 3.3176\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2315 - mae: 3.2315\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1632 - mae: 3.1632\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0943 - mae: 3.0943\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0249 - mae: 3.0249\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9549 - mae: 2.9549\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8846 - mae: 2.8846\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8139 - mae: 2.8139\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7546 - mae: 2.7546\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6693 - mae: 2.6693\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5958 - mae: 2.5958\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5222 - mae: 2.5222\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4486 - mae: 2.4486\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3750 - mae: 2.3750\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3013 - mae: 2.3013\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2415 - mae: 2.2415\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1651 - mae: 2.1651\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0865 - mae: 2.0865\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0164 - mae: 2.0164\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9459 - mae: 1.9459\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8750 - mae: 1.8750\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8037 - mae: 1.8037\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.7388 - mae: 1.7388\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6581 - mae: 1.6581\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5841 - mae: 1.5841\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5100 - mae: 1.5100\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4441 - mae: 1.4441\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3693 - mae: 1.3693\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2943 - mae: 1.2943\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2239 - mae: 1.2239\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1547 - mae: 1.1547\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0798 - mae: 1.0798\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0064 - mae: 1.0064\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9329 - mae: 0.9329\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8770 - mae: 0.8770\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7953 - mae: 0.7953\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7183 - mae: 0.7183\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6788 - mae: 0.6788\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5930 - mae: 0.5930\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f65331c9d90>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# However, it is not always the case that changing any one of the parameters might result in an improvement!\n",
        "\n",
        "# Usually make the smallest change possible. You do not necessarily always have to make big changes (e.g., adding 3 layers), you can just adjust one thing on your model, try it out and see how it goes!\n",
        "# Better do many, many small changes than big changes! So you can actually track what caused the improvement.\n",
        "\n",
        "# For example, next example is just adding another layer, keeping epochs at 100 and SGD optimizer"
      ],
      "metadata": {
        "id": "AKEU2Gt3aW4W"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPROVING THE PREVIOUS MODEL PERFORMANCE\n",
        "\n",
        "# Tweaking another hyperparameter, adding a hidden layer, making it a larger model from a small model...\n",
        "\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API, this time with an extra hidden layer with a 100 hidden units\n",
        "model = tf.keras.Sequential([  \n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),  \n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=[\"mae\"],  # the same as tf.keras.losses.mae\n",
        "              optimizer=\"sgd\",  # the same as tf.keras.optimizers.SGD()\n",
        "              metrics=[\"mae\"])  # metrics has to be always in a list                                                    \n",
        "\n",
        "# 3. Fit the model (keeping 100 epochs as previous change, it improved!)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM6cmOowb7Q9",
        "outputId": "5424eef9-3e69-4ef6-8b6a-a4a3f644a235"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 459ms/step - loss: 12.3185 - mae: 12.3185\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 11.7696 - mae: 11.7696\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.2132 - mae: 11.2132\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.6444 - mae: 10.6444\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.0534 - mae: 10.0534\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.4344 - mae: 9.4344\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.7821 - mae: 8.7821\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.0881 - mae: 8.0881\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.3552 - mae: 7.3552\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.5787 - mae: 6.5787\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.7437 - mae: 5.7437\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.8395 - mae: 4.8395\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.1104 - mae: 4.1104\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.0143 - mae: 4.0143\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9156 - mae: 3.9156\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9722 - mae: 3.9722\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9044 - mae: 3.9044\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9636 - mae: 3.9636\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9191 - mae: 3.9191\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9452 - mae: 3.9452\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9259 - mae: 3.9259\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9194 - mae: 3.9194\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9328 - mae: 3.9328\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8934 - mae: 3.8934\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.9399 - mae: 3.9399\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8726 - mae: 3.8726\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.9469 - mae: 3.9469\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8875 - mae: 3.8875\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.9223 - mae: 3.9223\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.8945 - mae: 3.8945\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8962 - mae: 3.8962\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9016 - mae: 3.9016\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.8700 - mae: 3.8700\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9089 - mae: 3.9089\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8473 - mae: 3.8473\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9242 - mae: 3.9242\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8570 - mae: 3.8570\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.8981 - mae: 3.8981\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8642 - mae: 3.8642\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.8718 - mae: 3.8718\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.8715 - mae: 3.8715\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.8453 - mae: 3.8453\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.8800 - mae: 3.8800\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8260 - mae: 3.8260\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8944 - mae: 3.8944\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8276 - mae: 3.8276\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8726 - mae: 3.8726\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8350 - mae: 3.8350\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8461 - mae: 3.8461\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.8426 - mae: 3.8426\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.8194 - mae: 3.8194\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.8563 - mae: 3.8563\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 3.7997 - mae: 3.7997\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.8659 - mae: 3.8659\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.7994 - mae: 3.7994\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.8460 - mae: 3.8460\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8070 - mae: 3.8070\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8191 - mae: 3.8191\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8148 - mae: 3.8148\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7959 - mae: 3.7959\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8305 - mae: 3.8305\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7721 - mae: 3.7721\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8384 - mae: 3.8384\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7722 - mae: 3.7722\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.8180 - mae: 3.8180\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7800 - mae: 3.7800\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7908 - mae: 3.7908\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7888 - mae: 3.7888\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7707 - mae: 3.7707\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.8038 - mae: 3.8038\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7432 - mae: 3.7432\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8120 - mae: 3.8120\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7460 - mae: 3.7460\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7888 - mae: 3.7888\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7540 - mae: 3.7540\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.7613 - mae: 3.7613\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7677 - mae: 3.7677\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7409 - mae: 3.7409\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7782 - mae: 3.7782\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7131 - mae: 3.7131\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7865 - mae: 3.7865\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7208 - mae: 3.7208\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7583 - mae: 3.7583\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7290 - mae: 3.7290\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7335 - mae: 3.7335\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7451 - mae: 3.7451\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7097 - mae: 3.7097\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7536 - mae: 3.7536\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.6883 - mae: 3.6883\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.7544 - mae: 3.7544\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.6966 - mae: 3.6966\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 3.7264 - mae: 3.7264\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.7051 - mae: 3.7051\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.7057 - mae: 3.7057\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7214 - mae: 3.7214\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6772 - mae: 3.6772\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7300 - mae: 3.7300\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6649 - mae: 3.6649\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7216 - mae: 3.7216\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6734 - mae: 3.6734\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f65331390d0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now mae, mean absolute error is about on average how wrong are our model's predictions, is almost half as before!\n",
        "# Let's remind ourselves of the data\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iABscS6ecH45",
        "outputId": "31b99619-031e-4529-b426-61bf1ec6a2bd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([17.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiDrpfodd2lY",
        "outputId": "4ee44d07-3578-4096-a35e-df31ae128826"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[31.38265]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seems model with just tweaking the epochs was better!! It was closer to the actual value.\n",
        "\n",
        "# However, even though the model seems to be better, the test accuracy is worse than before. \n",
        "# So, the model seems to be overfitting, that is, is learning the training data too well. \n",
        "# So it is learning the patterns between X and y far too well. \n",
        "# So when it sees a new X, it is just relating back to what it knows and the error that is producing during training is not a really valid representation of what it is actually doing.\n",
        "# The real way we do to evaluate ML models is not using the metrics that it gives from the training data but with the metrics we get from data it has never seen before (testing set data)."
      ],
      "metadata": {
        "id": "j3zC1Ikhd4jm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# So not all ways possible to improve a model lead to an actual improvement.\n",
        "# And also sometimes the metrics seen during training are not necessarily representative of the metrics obtained in data that the model has never seen before. The testing data, using data the model has never seen before, is the real evaluation/generalization power of the model."
      ],
      "metadata": {
        "id": "ronzrGNORokQ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ojDLrKqoSWCu"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Common ways to improve a deep model:\n",
        "\n",
        "* **Adding layers** (makes the model larger, more complex)\n",
        "* **Increase the number of hidden units** (makes the model larger, more complex)\n",
        "* **Change the activation functions**\n",
        "* **Change the optimization function** (tells the model how to improve)\n",
        "* **Change the learning rate** (tells the model how much to improve per step). *Potentially the most important hyperparameter you can change on all neural networks* \n",
        "* **Fitting on more data** (using a larger training set)\n",
        "* **Fitting for longer** (train for more epochs)\n",
        "\n",
        "There are called hyperparameters because we can alter them. They are like a dial on your neural network that you can adjust to see how it improves, whereas a parameter is usually the patterns (weights) a neural network learns, so we do not code them ourselves.\n",
        "\n",
        "In the previous example, adjusting the learning_rate parameter of the optimizar has resulted in the best improvement!\n"
      ],
      "metadata": {
        "id": "kNaw1m80R9V-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating a model\n",
        "\n",
        "As important as fitting a model to data is evaluating a model's performance. \n",
        "\n",
        "How do we tell exactly how good our model's predictions are or how good the pattern/relationships it has learned between X and y?\n",
        "\n",
        "In practice, a typical workflow you'll go through when building neural networks is:\n",
        "\n",
        "```\n",
        "Build a model -> fit it -> evaluate it -> tweak the model -> fit it -> evaluate it -> tweak it -> fit it -> evaluate it...\n",
        "````\n",
        "\n"
      ],
      "metadata": {
        "id": "dhzNgsLnV21R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you are building models you have to: experiment, experiment, experiment.\n",
        "\n",
        "While when it comes to evaluation...there are 3 words you should memorize:\n",
        "\n",
        "> \"Visualize, visualize, visualize\"\n",
        "\n",
        "It is a good idea to visualize: \n",
        "\n",
        "* **The data** - what data are we working with? What does it look like?\n",
        "* **The model itself** - what does our model look like?\n",
        "* **The training of the model** - how does a model perform while it learns?\n",
        "* **The predictions of the model** - how do the predictions of a model line up against the ground truth (the original labels)?"
      ],
      "metadata": {
        "id": "7-jhWRdoWTlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try these concepts on a larger problem...\n",
        "\n",
        "# Make a bigger data set\n",
        "\n",
        "X = tf.range(-100, 100, 4)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-3QSFytZnZm",
        "outputId": "45abd42e-7309-4e6b-8c31-3bceb851cc64"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make labels for the data set\n",
        "\n",
        "y = X + 10   # this is the function we want the model to learn\n",
        "y  # we have one y value for every X value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFC_BTagbpJH",
        "outputId": "da7796cb-9cb1-4237-8366-590e47edae40"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "6bGNUPshbulx",
        "outputId": "0b516953-76a7-4b46-aa9f-844c08c448da"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f65322f5ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The 3 data sets...(possibly the most important concept in ML)\n",
        "\n",
        "In ML you are not going to fit and evaluate on the same data set. In this regard, when you are working in ML problems you will often going to have three different sets of data:\n",
        "\n",
        "* **Training set** - the model learns from this data, which is typically 70-80% of the total data you have available. (e.g., course materials of a course)\n",
        "* **Validation set** - the model gets tuned on this data, so you would tweak different things and test the performance of the model in this data after these changes. This is typically 10-15% of the data available. (e.g., practice exam of a course)\n",
        "* **Test set** - the model gets evaluated on this data to test what it has learned. This set typically 10-15% of the total data available. (e.g., final exam of a course).\n",
        "\n",
        "Depending on how much data you have, sometimes you get rid of the validation set and just split into training and test set.\n",
        "\n",
        "The underlying goal here is **GENERALIZATION**, the ideal state that we want to achieve with the model, which regards to the ability of a ML model to perform well on data it has not seen before (not included in the training/dev set).\n"
      ],
      "metadata": {
        "id": "3ZqsHMjob96Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the length of how many samples we have\n",
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_3Ff1jmhYV3",
        "outputId": "256ad714-1797-4e5b-bd96-60a2fba40657"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# That's pretty small data set so we are going to skip the validation set for now\n",
        "# Let's create a 80-20 training-testing sets, so split the data into train and test sets\n",
        "X_train = X[:40] # first 40 are training samples (80% of the data)\n",
        "y_train = y[:40]\n",
        "\n",
        "X_test = X[40:] # last 10 are testing samples (20% of the data)\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)   # training and testing features, training and testing labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uG2nm-zj2mtY",
        "outputId": "1f89a424-51b7-4b66-bc24-f3d8acdd4e7f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10, 40, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's continue with visualizations for evaluation!"
      ],
      "metadata": {
        "id": "kK3VaHfI3SKL"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing the data\n",
        "\n",
        "Now we've got our data in training and testing sets...let's visualize it again!"
      ],
      "metadata": {
        "id": "5Ouxysn73lnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 7))   # figure size\n",
        "\n",
        "# plot training data in blue\n",
        "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\")  # our model will learn on this\n",
        "\n",
        "#plot test data in green\n",
        "plt.scatter(X_test, y_test, c=\"g\", label=\"Testing data\")  # want our model to be able to predict this (given X, what's y?)\n",
        "\n",
        "#show a legend\n",
        "plt.legend();   # semicolon is to not get a live output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "GjGIQNfS3xAI",
        "outputId": "f12c503c-ec14-4e9b-beb8-712467864d61"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Any time you can visualize your data, your model, your anything, it is a good idea to do it!\n",
        "# So that way is much easier to understand!"
      ],
      "metadata": {
        "id": "MK58GIna4QC0"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# So now we are going to build a neural network to take in the training data to learn the relationship between X and y, and then we want the model to learn the relationship in the training data so it can predict our testing data.\n",
        "# So if we feed the X values of our test data, we want the model to be able to predict the y values."
      ],
      "metadata": {
        "id": "1o0ecDsu4jnC"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's have a look at how to build a neural network for our data\n",
        "\n",
        "# 1. Create a model \n",
        "model = tf.keras.Sequential([  \n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,  \n",
        "              optimizer=tf.keras.optimizers.SGD(), \n",
        "              metrics=[\"mae\"])                                                  \n",
        "\n",
        "# 3. Fit the model \n",
        "#model.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)  # now we feed just X_train, y_train"
      ],
      "metadata": {
        "id": "NCoVTITK5Oj-"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing the model"
      ],
      "metadata": {
        "id": "OaAPR65M6scc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model.summary()  # will get an error if model not fit, use instead model.build() with input_shape argument\n",
        "# or provide an input_shape parameter to the first layer in the code above, let's do it this way!"
      ],
      "metadata": {
        "id": "WUqM7V5565l9"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[0], y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlKzFImW7z2z",
        "outputId": "2951592b-0a59-48c6-cb2c-cbd11c479060"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=int32, numpy=-100>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=-90>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a model which builds automatically by defining the input_shape argument in the first layer\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model (same as above)\n",
        "model = tf.keras.Sequential([  # sequential model runs from top to bottom\n",
        "    tf.keras.layers.Dense(1, input_shape=[1])  # input shape is one number/scalar, to predict 1 number/scalar\n",
        "])\n",
        "\n",
        "\n",
        "# 2. Compile the model (same as above)\n",
        "model.compile(loss=tf.keras.losses.mae,  \n",
        "              optimizer=tf.keras.optimizers.SGD(), \n",
        "              metrics=[\"mae\"])                                                  \n"
      ],
      "metadata": {
        "id": "sqZexGfJ66-k"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()  # now as input_shape is set, even if the model is not fit, it plots the model summary!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fOtCBsQ8GYI",
        "outputId": "767c152b-e496-493c-cbd9-a50521013a40"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling model.summary() shows us the layers that it contains, the output shape and the number of parameters of each layer.\n",
        "# Dense is another word for fully connected layer.\n",
        "# Fully connected means that all neurons on one layer are connected to all neurons on the previous and next layer.\n",
        "# \"Densely connected\" layer."
      ],
      "metadata": {
        "id": "CvpXZCLR8ITI"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary Output:\n",
        "\n",
        "* **Total params** - total number of parameters in the model (these are the patterns that the model is going to learn, the number of patterns it is going to try to learn in the relationship between X and y).\n",
        "* **Trainable parameters** - these are the parameters (patterns) the model can update as it trains.\n",
        "* **Non-trainable params** - these parameters are not updated during training (this is typical when you bring in already learned patterns or parameters from other models during *transfer learning*). \n",
        "\n",
        "**Resource**: For a more in-depth overview of the trainable parameters within a layer, check out MIT's introduction to deep learning video (https://introtodeeplearning.com). \n",
        "\n",
        "**Exercise**: Try playing around with the number of hidden units in the dense layer, see how that affects the number of parameters (total and trainable) by calling `model.summary()`."
      ],
      "metadata": {
        "id": "CpfPfA3r9L7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The actual parameters in a dense layer you will probably find something called WEIGHTS MATRIX and BIAS VECTOR.\n",
        "# These are the trainable/learnable parameters (patterns) in a NN."
      ],
      "metadata": {
        "id": "YvxHj9eh9r_b"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's fit our model to the training data (step 3 before)\n",
        "\n",
        "model.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100, verbose=0) # verbose does not show anything during training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dX37bEkDGQw",
        "outputId": "6ae304f3-2dd7-4f46-d182-3776ce2ede08"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6533317bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# As we are running this continually, every time we run the cell of fit again (step 3), it actually fits the model for an extra hundred epochs.\n",
        "# To reset that, you have to reinstantiate the model (steps 1 and 2)"
      ],
      "metadata": {
        "id": "OgUDSyTMDa4g"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of our model and play with the number of hidden units to see how it affects the number of parameters\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "li2qRpmwT-vz",
        "outputId": "c0602380-3adb-4a04-bc33-56996d86b357"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create a model (same as above)\n",
        "model = tf.keras.Sequential([  # sequential model runs from top to bottom\n",
        "    tf.keras.layers.Dense(10, input_shape=[1])  # input shape is one number/scalar, to predict 1 number/scalar\n",
        "])\n",
        "\n",
        "\n",
        "# 2. Compile the model (same as above)\n",
        "model.compile(loss=tf.keras.losses.mae,  \n",
        "              optimizer=tf.keras.optimizers.SGD(), \n",
        "              metrics=[\"mae\"])    \n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrfuHcE3UJFd",
        "outputId": "a6a07850-7fc5-4527-832e-662518e68c76"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 10)                20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20\n",
            "Trainable params: 20\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seems to be 2 trainable parameters per hidden unit (i.e., a weight and a bias per unit)"
      ],
      "metadata": {
        "id": "cmL0tdVBUXk_"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Another way to visualize the model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model, show_shapes=True)  # dot format image of the model\n",
        "# show_shapes = True as this is going to take a lot of time making sure our input/output shapes are correct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "da7MhkVLUogn",
        "outputId": "66c3e9d2-85c4-4153-c195-f06cde4c1ec8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing a bit the model to see the plot\n",
        "\n",
        "# 1. Create a model (same as above)\n",
        "model = tf.keras.Sequential([  # sequential model runs from top to bottom\n",
        "    tf.keras.layers.Dense(10, input_shape=[1], name=\"Input_Layer\"),\n",
        "    tf.keras.layers.Dense(1, name=\"Output_Layer\")\n",
        "], name = \"Model_1\")\n",
        "\n",
        "\n",
        "# 2. Compile the model (same as above)\n",
        "model.compile(loss=tf.keras.losses.mae,  \n",
        "              optimizer=tf.keras.optimizers.SGD(), \n",
        "              metrics=[\"mae\"])    \n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19KPddmSU_DD",
        "outputId": "2f89ae73-c218-42e4-8e85-4984b7667cae"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input_Layer (Dense)         (None, 10)                20        \n",
            "                                                                 \n",
            " Output_Layer (Dense)        (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with the parameter name set, now everything has a specific name!\n",
        "# it is very helpful when you have many layers, to know which is which\n",
        "\n",
        "plot_model(model, show_shapes=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "WhQacVrrVqPi",
        "outputId": "237b55fc-dbc8-4598-f8e5-9eaaf260fc25"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing our model's predictions\n",
        "\n",
        "To visualize predictions, it is a good idea to plot them against the ground truth labels.\n",
        "\n",
        "Often you'll see this in the form of `y_test` or `y_true` versus `y_pred` (ground truth versus your model's predictions)."
      ],
      "metadata": {
        "id": "MjCboC1qVtD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100, verbose=0) # verbose does not show anything during training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-VyOb3dfRfZ",
        "outputId": "555eb269-0934-4e9e-8e24-09f5f69aad0a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f65330e4bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred  # we get a tensor in the same format as y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iOA_SLwW_rL",
        "outputId": "82fb684a-cf9e-4f8e-9fbb-d0c49df136ac"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 75.978065],\n",
              "       [ 80.92622 ],\n",
              "       [ 85.87439 ],\n",
              "       [ 90.82255 ],\n",
              "       [ 95.77071 ],\n",
              "       [100.718864],\n",
              "       [105.66703 ],\n",
              "       [110.61519 ],\n",
              "       [115.563354],\n",
              "       [120.51152 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhqRws0Ie5TC",
        "outputId": "c7a7bc1e-8e26-43bc-9d4d-75470738692e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In an ideal world, they would be the exact same numbers. If the model learned the data perfectly and could predict the test data set 100% correctly."
      ],
      "metadata": {
        "id": "R3KxfgiyfVH7"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: If you feel like you're going to reuse some kind of functionality in the future, it is a good idea to turn it into a function."
      ],
      "metadata": {
        "id": "9yo8PeUlfywT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a plotting function\n",
        "def plot_predictions(train_data=X_train,   # all have default values\n",
        "                     train_labels=y_train,\n",
        "                     test_data=X_test,\n",
        "                     test_labels=y_test,\n",
        "                     predictions=y_pred):\n",
        "  \"\"\"\n",
        "  Plots training data, test data and compares predictions to ground truth labels.\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
        "  # Plot testing data in green\n",
        "  plt.scatter(test_data, test_labels, c=\"g\", label=\"Testing data\")\n",
        "  # Plot model's predictions in red\n",
        "  plt.scatter(test_data, predictions, c=\"r\", label=\"Predictions\")\n",
        "  # Show legend\n",
        "  plt.legend();\n",
        "\n",
        "plot_predictions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "3yATkyp0fsS-",
        "outputId": "a8206e52-930e-4414-f150-1d5e94301726"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This graph shows quite well the performance in a fast and compelling way!\n",
        "# The predictions do not seem bad, however depending on the scale, the distance between the predictions and the test data might be fairly large, indicating a large error.\n",
        "# So, the best way to figure this out is with some evaluation metrics!"
      ],
      "metadata": {
        "id": "rBVMy8C9gsBI"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating our model's predictions with regression evaluation metrics\n",
        "\n",
        "Depending on the problem you are working on, there will be different evaluation metrics to evaluate your model's performance. \n",
        "\n",
        "Since we're working on a regression problem, two of the main metrics, plus an extra one:\n",
        "* **MAE** - mean absolute error, \"on average, how wrong is each of my model's predictions\". Use: great starter metric for any regression problem.\n",
        "* **MSE** - mean square error, \"square the average errors\". Use: when larger error are more significant than smaller errors (as the square amplifies the impact of larger errors on the value).\n",
        "* **Huber loss** - combination of MSE and MAE. Use: it is less sensitive to outliers than MSE."
      ],
      "metadata": {
        "id": "ucOjKfCUlKLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTyn4Bf5lqzl",
        "outputId": "a0a97f22-f9af-41c4-8fae-05d6e388b4a7"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 243ms/step - loss: 10.2448 - mae: 10.2448\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10.244787216186523, 10.244787216186523]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In this case loss and evaluation metric is the same as we used the same metric for both things.\n",
        "\n",
        "# What if you want to compute another performance metric on their own? By not calling the evaluation method..."
      ],
      "metadata": {
        "id": "5bTIgjiUnYjR"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the Mean Absolute Error to compare y_pred to y_test, without using evaluate method!\n",
        "mae_loss = tf.metrics.mean_absolute_error(y_true = y_test, \n",
        "                                          y_pred = y_pred)\n",
        "mae_loss, tf.reduce_mean(mae_loss)   # individual loss for each sample, and the mae (average)\n",
        "# but also it actually does it well if both tensors are of the same shape, originally they are not"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeuAKkHDoNIv",
        "outputId": "0693ee11-b2de-4a0e-9527-8ba06514a7cc"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              " array([13.613161 , 11.22951  , 10.025122 , 10.16451  , 11.5082855,\n",
              "        14.031319 , 17.733624 , 22.615189 , 27.563354 , 32.51152  ],\n",
              "       dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=17.09956>)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred, y_test # they have a different shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ1mQVEP2uDG",
        "outputId": "fef99989-f43e-4b76-8729-4b5572818af2"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 75.978065],\n",
              "        [ 80.92622 ],\n",
              "        [ 85.87439 ],\n",
              "        [ 90.82255 ],\n",
              "        [ 95.77071 ],\n",
              "        [100.718864],\n",
              "        [105.66703 ],\n",
              "        [110.61519 ],\n",
              "        [115.563354],\n",
              "        [120.51152 ]], dtype=float32),\n",
              " <tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.squeeze(y_pred) # to get rid of the additional empty/single dimension"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJR7p_fa1PWe",
        "outputId": "2f1883ff-9089-4839-889a-f9d914c93e88"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([ 75.978065,  80.92622 ,  85.87439 ,  90.82255 ,  95.77071 ,\n",
              "       100.718864, 105.66703 , 110.61519 , 115.563354, 120.51152 ],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae_loss = tf.metrics.mean_absolute_error(y_true = y_test, \n",
        "                                          y_pred = tf.squeeze(y_pred))\n",
        "mae_loss  # now it computes the average well! when the shapes match! Now both y_test and y_pred are shape = (10,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3w7kS_O2PE1",
        "outputId": "55da8ef8-9221-4132-e755-e3e174a5c092"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=10.24479>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the Mean Squared Error\n",
        "mse_loss = tf.metrics.mean_squared_error(y_true = y_test,\n",
        "                                        y_pred = tf.squeeze(y_pred))\n",
        "mse_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4RAuqBS2RMP",
        "outputId": "00d035b9-0ae2-437e-8917-ea8e965761f6"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=112.37256>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Good!!! MSE will be typically higher than MAE, as MSE squares the errors, which are typically larger!\n",
        "# Use MSE when larger errors matter more than small errors!!"
      ],
      "metadata": {
        "id": "k_Sw81A73Jsv"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some functions to reuse MAE and MSE\n",
        "def mae(y_true, y_pred):\n",
        "  return tf.metrics.mean_absolute_error(y_true = y_test,\n",
        "                                        y_pred = y_pred)\n",
        "  \n",
        "def mse(y_true, y_pred):\n",
        "  return tf.metrics.mean_squared_error(y_true = y_test,\n",
        "                                        y_pred = y_pred)"
      ],
      "metadata": {
        "id": "p2ukAT7n3vg5"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running experiments to improve our model (minimize the difference between our model predictions and the test labels)\n",
        "\n",
        "```\n",
        "Build a model -> fit it -> evaluate it -> tweak it -> fit it -> evaluate it -> tweak it -> fit it -> evaluate it...\n",
        "\n",
        "Ways to improve our model:\n",
        "\n",
        "1. **Get more data** - get more examples for your model to train on (more opportunities to learn patterns or relationships between features and labels).\n",
        "2.  **Make your model larger** (using a **more complex** model) - this might come in the form of more layers, or more hidden units in each layer.\n",
        "3. **Train for longer** - give your longer more of a chance to find patterns in the data.\n",
        "\n",
        "Let's do three modeling experiments (we will not use more data, so we will test the other two options):\n",
        "\n",
        "1. `model_1` - same as the original model, 1 layer, trained for 100 epochs.\n",
        "2. `model_2` - 2 layers, trained for 100 epochs.\n",
        "3. `model_3` - 2 layers, trained for 500 epochs.\n",
        "\n",
        "*Mindset*: start with a baseline model, and then run modeling miniexperiments tweaking one of the parameters for the next experiment. And then do the same for the next experiment, and so on."
      ],
      "metadata": {
        "id": "mybA2Mxb4KU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Machine learning explorer's motto -> \"Visualize, visualize, visualize\".\n",
        "##### That is, taking a look to everything: data, model, training and predictions. As much as possible and as often as possible!\n"
      ],
      "metadata": {
        "id": "4L_ydwccmga3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Machine learning practitioner's motto -> \"Experiment, experiment, experiment\"\n",
        "\n",
        "##### That is, run a series of experiments to see if we can improve the model following the workflow above (build a model, fit it, evaluate it, tweak it...)"
      ],
      "metadata": {
        "id": "em2ztacynEuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2mW2or4nLhW",
        "outputId": "947d9746-817b-4d43-af8c-336e95d913b4"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
              " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "          32,   36,   40,   44,   48,   52,   56], dtype=int32)>,\n",
              " <tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
              " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "         66], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build `model_1`**"
      ],
      "metadata": {
        "id": "lNWs-jJ3owG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_1.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_1.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grS59Wbdpumy",
        "outputId": "dd1ab107-8748-4ae9-90cb-a1b2b7c08dcb"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 9ms/step - loss: 15.9024 - mae: 15.9024\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.2837 - mae: 11.2837\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.1074 - mae: 11.1074\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.2991 - mae: 9.2991\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.1677 - mae: 10.1677\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.4303 - mae: 9.4303\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.5704 - mae: 8.5704\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.0442 - mae: 9.0442\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.7517 - mae: 18.7517\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.1142 - mae: 10.1142\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3980 - mae: 8.3980\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.6639 - mae: 10.6639\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.7977 - mae: 9.7977\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.0103 - mae: 16.0103\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.4068 - mae: 11.4068\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.5393 - mae: 8.5393\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.6348 - mae: 13.6348\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.4629 - mae: 11.4629\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.9148 - mae: 17.9148\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.0494 - mae: 15.0494\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.0216 - mae: 11.0216\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 8.1558 - mae: 8.1558\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.5138 - mae: 9.5138\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.6617 - mae: 7.6617\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.1859 - mae: 13.1859\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.4211 - mae: 16.4211\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.1660 - mae: 13.1660\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.2559 - mae: 14.2559\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.0670 - mae: 10.0670\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.3409 - mae: 16.3409\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.6444 - mae: 23.6444\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6215 - mae: 7.6215\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3221 - mae: 9.3221\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.7313 - mae: 13.7313\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.1276 - mae: 11.1276\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.3222 - mae: 13.3222\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.4763 - mae: 9.4763\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 10.1381 - mae: 10.1381\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10.1793 - mae: 10.1793\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.9137 - mae: 10.9137\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.9063 - mae: 7.9063\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.0914 - mae: 10.0914\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.7006 - mae: 8.7006\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.2047 - mae: 12.2047\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.7970 - mae: 13.7970\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.4687 - mae: 8.4687\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.1330 - mae: 9.1330\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.6190 - mae: 10.6190\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7503 - mae: 7.7503\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.5407 - mae: 9.5407\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.1584 - mae: 9.1584\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.3630 - mae: 16.3630\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.1299 - mae: 14.1299\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.1247 - mae: 21.1247\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.3961 - mae: 16.3961\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.9806 - mae: 9.9806\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.9606 - mae: 9.9606\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.2209 - mae: 9.2209\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 8.4239 - mae: 8.4239\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.4869 - mae: 9.4869\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.4355 - mae: 11.4355\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.6887 - mae: 11.6887\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.9675 - mae: 16.9675\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.4599 - mae: 12.4599\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.0184 - mae: 13.0184\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.0600 - mae: 8.0600\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.1888 - mae: 10.1888\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.3633 - mae: 12.3633\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.0516 - mae: 9.0516\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.0378 - mae: 10.0378\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.0516 - mae: 10.0516\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.6151 - mae: 12.6151\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.3819 - mae: 10.3819\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.7229 - mae: 9.7229\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.2252 - mae: 11.2252\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3642 - mae: 8.3642\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.1274 - mae: 9.1274\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 19.5039 - mae: 19.5039\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.8945 - mae: 14.8945\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.0034 - mae: 9.0034\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.0206 - mae: 13.0206\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.9299 - mae: 7.9299\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.6872 - mae: 7.6872\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.0328 - mae: 10.0328\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.2433 - mae: 9.2433\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.0209 - mae: 12.0209\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.6389 - mae: 10.6389\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.2667 - mae: 7.2667\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.7786 - mae: 12.7786\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.3481 - mae: 7.3481\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7175 - mae: 7.7175\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1263 - mae: 7.1263\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.6190 - mae: 12.6190\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.0912 - mae: 10.0912\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.3558 - mae: 9.3558\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.6834 - mae: 12.6834\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.6762 - mae: 8.6762\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.4693 - mae: 9.4693\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.7067 - mae: 8.7067\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6533015790>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make and plot predictions for model_1\n",
        "y_preds_1 = model_1.predict(X_test)   # the test has to be on data that the model has never seen before!\n",
        "plot_predictions(predictions = y_preds_1)   # the other paramaters are hardcoded (default values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "7qh1bPTlqmkx",
        "outputId": "12312894-1096-4663-ef9f-1552401ec58e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6533a75290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_1 evaluation metrics\n",
        "mae_1 = mae(y_test, tf.squeeze(y_preds_1)) #squeeze works in this case so they have the same shape!! We get rid of the single dimension there and have both (10,)\n",
        "mse_1 = mse(y_test, tf.squeeze(y_preds_1)) \n",
        "mae_1, mse_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdDzgGTRrQz7",
        "outputId": "a3923939-06c2-4a3f-ccb1-959c5e628088"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=18.745327>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=353.57336>)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# So on average, each dot is 18.74 away from where it should be!\n",
        "# When we square the errors, then there is less easy interpretation about it! Larger error value!"
      ],
      "metadata": {
        "id": "nMKo-B-fsBpA"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Built `model_2`**"
      ],
      "metadata": {
        "id": "dJT81IUCtHJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 dense (or fully connected) layers, trained for 100 epochs\n",
        "\n",
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#1. Create the model\n",
        "\n",
        "model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10),   # number of units is kind of arbitrary, we will try this experiment with 10, but could be a different value\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "#2. Compile the model\n",
        "\n",
        "model_2.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mse\"])  # we will try a different one, but as long as we do not change the loss, it is the same\n",
        "\n",
        "#3. Fit the model\n",
        "model_2.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F3nTF_TtKYw",
        "outputId": "193e8ae6-746e-439f-8408-a7a35d122cde"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 12ms/step - loss: 27.4058 - mse: 1084.1482\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24.6339 - mse: 777.9203\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 29.8935 - mse: 1334.8955\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 27.4055 - mse: 1106.8035\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.9463 - mse: 281.1077\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.8819 - mse: 168.6621\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 11.1988 - mse: 151.3509\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.0910 - mse: 160.3745\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 40.4763 - mse: 2586.0090\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 27.8688 - mse: 1094.4382\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.2473 - mse: 147.9359\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 25.2803 - mse: 890.3867\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 16.9897 - mse: 399.9678\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 25.9217 - mse: 1049.5515\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.9948 - mse: 450.2580\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.3510 - mse: 80.6206\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.8636 - mse: 174.7868\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 19.5304 - mse: 565.8053\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.3469 - mse: 167.7749\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 17.6985 - mse: 455.7096\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 15.8984 - mse: 347.1929\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.1991 - mse: 285.1767\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.7720 - mse: 91.7852\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.0570 - mse: 153.7430\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.6838 - mse: 233.2949\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 26.1877 - mse: 1024.6091\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.7432 - mse: 194.8454\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 22.8730 - mse: 835.6074\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.2459 - mse: 96.7786\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 29.2641 - mse: 1535.1349\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 53.0225 - mse: 5030.2988\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.9951 - mse: 211.7025\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.6357 - mse: 337.3666\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.6925 - mse: 214.4823\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.2398 - mse: 92.9126\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.6497 - mse: 403.6573\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 11.0382 - mse: 192.3919\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.1634 - mse: 433.6717\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 19.1013 - mse: 529.6439\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 20.4324 - mse: 610.1324\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.9102 - mse: 279.6183\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.2809 - mse: 186.6180\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.7333 - mse: 167.0952\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 23.0260 - mse: 830.4244\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.3897 - mse: 128.9549\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.7904 - mse: 181.9212\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6438 - mse: 153.8708\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.2335 - mse: 402.8494\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.5729 - mse: 99.8337\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.8185 - mse: 260.3670\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11.5958 - mse: 154.7956\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 30.5538 - mse: 1613.0886\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.3541 - mse: 302.5293\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 23.9713 - mse: 859.3983\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 23.1938 - mse: 805.5452\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.8837 - mse: 170.9834\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.7445 - mse: 198.7015\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.5995 - mse: 102.5890\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.5172 - mse: 216.3367\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.3200 - mse: 208.6371\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 17.4604 - mse: 428.6393\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.6052 - mse: 136.9777\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.4893 - mse: 152.4555\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 24.8450 - mse: 911.7511\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.6761 - mse: 142.7374\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.7809 - mse: 704.4492\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.7136 - mse: 136.0194\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.6397 - mse: 149.2300\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22.6914 - mse: 742.1761\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.3316 - mse: 166.1628\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.4355 - mse: 323.0843\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.7437 - mse: 67.0210\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.6891 - mse: 183.7296\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24.0400 - mse: 908.8992\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.5896 - mse: 149.3948\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.4371 - mse: 188.3310\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.6489 - mse: 429.2708\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.0614 - mse: 95.4870\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 23.9675 - mse: 864.0864\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 26.7463 - mse: 1104.4032\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.6714 - mse: 170.7055\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.0228 - mse: 211.9191\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.4218 - mse: 395.5589\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.2629 - mse: 73.0935\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 14.9650 - mse: 312.8361\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.2862 - mse: 315.3605\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 19.1086 - mse: 521.2534\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 29.8229 - mse: 1287.1907\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.1742 - mse: 124.1342\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 21.5240 - mse: 663.8611\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.5716 - mse: 161.7467\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 18.3977 - mse: 464.1326\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 7.4138 - mse: 81.9820\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.7380 - mse: 445.7379\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.1144 - mse: 164.0820\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 19.4346 - mse: 510.5842\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 12.1593 - mse: 209.9755\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.5653 - mse: 169.4052\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.8827 - mse: 265.4630\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 20.2277 - mse: 608.8218\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6532ee8690>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make and plot predictions for model_2\n",
        "y_preds_2 = model_2.predict(X_test)  \n",
        "plot_predictions(predictions = y_preds_2) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "TrQzT0HouBWl",
        "outputId": "c9107bfe-3c3c-4003-aa89-2ef65272ac72"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6533368320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_2 evaluation metrics\n",
        "mae_2 = mae(y_test, tf.squeeze(y_preds_2))\n",
        "mse_2 = mse(y_test, tf.squeeze(y_preds_2)) \n",
        "mae_2, mse_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0zOK2b4uPPy",
        "outputId": "c2fddce2-1f56-4607-b562-2334a50fdb08"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=3.1969407>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=13.070143>)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build `model_3`**"
      ],
      "metadata": {
        "id": "6KX13S7ouVTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train for longer, 500 epochs, with 2 layers.\n",
        "\n",
        "# 1. Build the model\n",
        "model_3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)   #this is the output layer!\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_3.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mse\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_3.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRJrnsvqvNuB",
        "outputId": "bb169e72-24c7-4e82-b814-41b9e5e02ebf"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 1s 8ms/step - loss: 42.5822 - mse: 2823.1755\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.9331 - mse: 167.2227\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 26.9259 - mse: 1062.6483\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.6703 - mse: 247.0116\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 15.1926 - mse: 292.5402\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.0801 - mse: 177.9818\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.4040 - mse: 158.0894\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1956 - mse: 171.4060\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 41.6513 - mse: 2760.7690\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 28.8935 - mse: 1179.5691\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.5332 - mse: 96.3214\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 27.4635 - mse: 1036.9036\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.1139 - mse: 174.4626\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 34.8373 - mse: 1995.2262\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.6692 - mse: 730.1407\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 9.9359 - mse: 125.0452\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 17.8992 - mse: 425.5909\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.3769 - mse: 328.2471\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 14.4871 - mse: 330.6522\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 10.4799 - mse: 148.3128\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 15.2574 - mse: 316.1354\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.6024 - mse: 335.8524\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.2279 - mse: 118.5867\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.2281 - mse: 406.3126\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.9113 - mse: 332.4176\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 20.8721 - mse: 646.5103\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 26.0935 - mse: 1063.5781\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.5731 - mse: 546.2322\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.2419 - mse: 97.0285\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 29.1981 - mse: 1526.2473\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 52.8950 - mse: 5004.9385\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11.9662 - mse: 209.8554\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.5894 - mse: 335.2045\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.6582 - mse: 212.6496\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.2225 - mse: 92.4001\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.5907 - mse: 400.5735\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.0521 - mse: 192.2627\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 18.1794 - mse: 434.8008\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.1155 - mse: 531.0634\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 20.4601 - mse: 611.7039\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.8707 - mse: 277.6567\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.2499 - mse: 184.9444\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.7146 - mse: 165.5856\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.9474 - mse: 824.3484\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.3634 - mse: 128.6935\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.7521 - mse: 179.9454\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.6556 - mse: 153.6267\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.2632 - mse: 404.3502\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.5489 - mse: 99.3150\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.7777 - mse: 258.1375\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.5782 - mse: 154.1093\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 30.4587 - mse: 1602.0035\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.3112 - mse: 300.4779\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.8976 - mse: 853.5265\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 23.1125 - mse: 799.5634\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.8542 - mse: 171.0030\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.7053 - mse: 197.2424\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5760 - mse: 102.2686\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.4807 - mse: 214.1996\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.8913 - mse: 192.4133\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.9716 - mse: 403.6736\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.3876 - mse: 131.0050\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.3428 - mse: 140.0835\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 24.1942 - mse: 861.5433\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.5224 - mse: 133.7910\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.2046 - mse: 663.3076\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.5191 - mse: 129.0164\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.3680 - mse: 311.3400\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.6097 - mse: 129.1470\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.6937 - mse: 204.9402\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.1234 - mse: 232.2865\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 19.6276 - mse: 547.0938\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.1902 - mse: 191.1925\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.9121 - mse: 747.2980\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1885 - mse: 71.3460\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.4161 - mse: 149.7082\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 22.0473 - mse: 726.7158\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.7011 - mse: 475.9111\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.8612 - mse: 323.3845\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.1842 - mse: 967.9949\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.9252 - mse: 141.4076\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.7402 - mse: 232.0013\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.5086 - mse: 399.6932\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.2803 - mse: 73.0742\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.0318 - mse: 315.4439\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.3400 - mse: 316.7400\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 19.2179 - mse: 526.2452\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 29.5362 - mse: 1260.8318\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 10.1332 - mse: 124.0810\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.2860 - mse: 648.9022\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.5150 - mse: 162.7650\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 18.1815 - mse: 452.6951\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 6.5368 - mse: 60.3852\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.1743 - mse: 155.9370\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 24.6366 - mse: 911.7822\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 10.7835 - mse: 171.5015\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.5303 - mse: 366.1720\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.0533 - mse: 143.2887\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.8684 - mse: 139.1626\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 27.1543 - mse: 1124.8951\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.0985 - mse: 342.1706\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.6480 - mse: 158.1153\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1251 - mse: 96.3347\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 23.5916 - mse: 833.3981\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.7488 - mse: 156.5293\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.2126 - mse: 173.6958\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 21.1606 - mse: 667.0150\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.3044 - mse: 56.9973\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.5376 - mse: 132.1062\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.4890 - mse: 134.2514\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.6339 - mse: 390.5507\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.4794 - mse: 118.5018\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.5285 - mse: 446.8936\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.8953 - mse: 425.6241\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.0144 - mse: 150.0812\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 22.9330 - mse: 765.0790\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 9.4916 - mse: 126.5410\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 10.5481 - mse: 136.6725\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.0094 - mse: 75.7835\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 29.2342 - mse: 1273.1959\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.0499 - mse: 70.0146\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 27.9400 - mse: 1195.5651\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 32.4459 - mse: 1544.1790\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 19.2868 - mse: 551.3378\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.4754 - mse: 152.0530\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5574 - mse: 112.7099\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 12.6759 - mse: 251.0630\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.7723 - mse: 225.5731\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.9047 - mse: 310.4759\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 10.2031 - mse: 121.1963\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 21.6633 - mse: 710.6754\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.2481 - mse: 95.4219\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.0299 - mse: 112.2258\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 16.8696 - mse: 414.9005\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 10.6254 - mse: 149.2570\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 18.4895 - mse: 484.5710\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 23.4743 - mse: 744.1520\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.2535 - mse: 139.1044\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.9906 - mse: 142.8344\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.9579 - mse: 414.4421\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.2991 - mse: 75.2643\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 34.0529 - mse: 2006.5125\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 23.0925 - mse: 746.3925\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 11.3178 - mse: 228.5257\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 25.0260 - mse: 849.0702\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11.1395 - mse: 168.5864\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 14.0641 - mse: 293.4109\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.9134 - mse: 392.8133\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.2440 - mse: 108.5677\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.9228 - mse: 71.5231\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 16.5267 - mse: 392.8456\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.7869 - mse: 119.3237\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 26.8916 - mse: 1022.6859\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.8991 - mse: 238.7717\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 15.2670 - mse: 334.6252\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.6285 - mse: 423.5635\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 19.3260 - mse: 576.5461\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.2555 - mse: 129.2181\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.9670 - mse: 109.4624\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 20.9312 - mse: 658.5391\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 23.8384 - mse: 862.0272\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 18.7474 - mse: 501.8240\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 17.6969 - mse: 449.2838\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.0904 - mse: 180.7385\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.5959 - mse: 181.1625\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 21.5284 - mse: 678.8081\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 26.4465 - mse: 1062.5342\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.8807 - mse: 118.7010\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 22.7214 - mse: 798.4161\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.1229 - mse: 196.9343\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 17.9795 - mse: 500.4771\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 28.9997 - mse: 1322.0027\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.6552 - mse: 438.1519\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.1959 - mse: 200.8898\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 27.5433 - mse: 1094.9504\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.3104 - mse: 78.4074\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.2890 - mse: 109.4852\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.2729 - mse: 472.1316\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.5415 - mse: 146.4986\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 7.9188 - mse: 99.8195\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 17.5086 - mse: 443.7149\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.0546 - mse: 158.4256\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.7519 - mse: 205.5672\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 30.5715 - mse: 1403.3210\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.5400 - mse: 99.1817\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.9406 - mse: 367.1970\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.5711 - mse: 85.4119\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 28.8885 - mse: 1189.3575\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 13.1373 - mse: 271.7828\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 18.2753 - mse: 510.0540\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 13.6973 - mse: 263.4832\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.6935 - mse: 261.3924\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 28.5525 - mse: 1132.8036\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.1046 - mse: 78.4306\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.0502 - mse: 75.1576\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 21.9599 - mse: 706.8632\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.9412 - mse: 649.9000\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.5266 - mse: 238.3850\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 17.9922 - mse: 464.4320\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 13.8247 - mse: 285.4791\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.0285 - mse: 51.1427\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 22.8397 - mse: 743.8772\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.9404 - mse: 153.3701\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.8189 - mse: 531.1255\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.3440 - mse: 126.9607\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.4134 - mse: 143.1123\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 21.1017 - mse: 676.7733\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 16.4626 - mse: 390.1864\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.3688 - mse: 318.3079\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 19.3789 - mse: 547.2064\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 10.2959 - mse: 146.6228\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 20.1656 - mse: 610.1119\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.0622 - mse: 308.3857\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.6038 - mse: 294.3999\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 23.3325 - mse: 801.2407\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.3112 - mse: 276.4134\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 9.8162 - mse: 134.9392\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.5853 - mse: 207.6590\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.3331 - mse: 39.2400\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.6926 - mse: 283.6680\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 33.5385 - mse: 1536.9210\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 13.8805 - mse: 237.5947\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.9872 - mse: 179.5804\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.9380 - mse: 333.4514\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 16.9834 - mse: 374.1158\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 16.1735 - mse: 385.0339\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.4892 - mse: 384.8622\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.9334 - mse: 185.4483\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.8279 - mse: 443.1905\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.4489 - mse: 310.3665\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 20.8729 - mse: 654.1624\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 20.4368 - mse: 593.8237\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.0925 - mse: 339.1686\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.9611 - mse: 65.8800\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.7431 - mse: 348.3255\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.6844 - mse: 71.0751\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.5997 - mse: 113.9802\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7600 - mse: 87.7894\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 15.6674 - mse: 373.7038\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.0044 - mse: 109.0671\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.4320 - mse: 279.9268\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 8.8925 - mse: 107.6465\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.3309 - mse: 570.3681\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.8752 - mse: 271.2403\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.5270 - mse: 282.7282\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.6643 - mse: 361.3552\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 17.4968 - mse: 411.0749\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.0650 - mse: 249.5704\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.4143 - mse: 283.6946\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 27.8084 - mse: 1100.5496\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4941 - mse: 68.9760\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 38.2515 - mse: 2418.7190\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 23.1391 - mse: 752.5808\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.2848 - mse: 78.3130\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 24.6464 - mse: 877.5939\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.3952 - mse: 219.4529\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.5623 - mse: 163.2278\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.1943 - mse: 306.4812\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.2490 - mse: 186.7467\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 31.6272 - mse: 1527.5117\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.1654 - mse: 178.0813\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.0203 - mse: 139.2419\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 8.9338 - mse: 103.4200\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.5165 - mse: 651.3102\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.4335 - mse: 198.8170\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.2669 - mse: 254.3578\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.0636 - mse: 233.3604\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.7188 - mse: 673.9230\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 32.9129 - mse: 1625.3516\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 9.7237 - mse: 132.0538\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 7.7036 - mse: 111.9084\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 28.5088 - mse: 1116.6100\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.3695 - mse: 83.2381\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.3200 - mse: 45.0157\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 37.1489 - mse: 2116.9194\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.2746 - mse: 108.5946\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 27.9333 - mse: 1069.9875\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.6131 - mse: 213.1038\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.0592 - mse: 386.4379\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 21.1418 - mse: 676.8713\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 24.0278 - mse: 882.7163\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 8.2943 - mse: 97.3966\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 9.0376 - mse: 119.3082\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 22.9683 - mse: 784.2509\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.8141 - mse: 226.1993\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.7266 - mse: 65.8700\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 20.9356 - mse: 635.6024\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.1900 - mse: 202.7065\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.4182 - mse: 239.8832\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 16.9540 - mse: 392.3293\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 17.3521 - mse: 445.1961\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 11.4509 - mse: 322.7451\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.2686 - mse: 277.3376\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 21.1963 - mse: 695.3914\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 15.7475 - mse: 357.8203\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.8710 - mse: 63.3629\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11.8133 - mse: 249.1276\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 23.6499 - mse: 815.9683\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 16.6366 - mse: 416.7855\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.7560 - mse: 54.9480\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 23.8761 - mse: 799.5335\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 7.9915 - mse: 87.4721\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 20.4030 - mse: 611.2331\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 13.1574 - mse: 265.1959\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 6.9126 - mse: 96.9808\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.5340 - mse: 480.4102\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6451 - mse: 185.5468\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.2383 - mse: 631.4930\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.2506 - mse: 310.1762\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 5.0876 - mse: 43.8700\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 13.8201 - mse: 261.3069\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 30.3948 - mse: 1275.1405\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 6.9042 - mse: 105.5144\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 11.0914 - mse: 282.4758\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 23.3471 - mse: 794.3978\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 14.8040 - mse: 338.8552\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 20.4903 - mse: 573.8469\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 8.6387 - mse: 102.4862\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 15.1350 - mse: 357.6274\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 8.2728 - mse: 98.8202\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 14.5406 - mse: 314.2698\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 12.8420 - mse: 242.4669\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 19.1403 - mse: 562.0199\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 16.9096 - mse: 427.4317\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 9.3109 - mse: 209.7535\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 19.9790 - mse: 608.7684\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 27.9554 - mse: 1118.0934\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 11.7384 - mse: 229.6228\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 16.4214 - mse: 408.3331\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.2757 - mse: 79.5801\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.4687 - mse: 775.1058\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 13.2669 - mse: 271.4508\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.0931 - mse: 163.5907\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.5639 - mse: 93.5884\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.2410 - mse: 53.8201\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 34.4345 - mse: 1928.3678\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 26.8680 - mse: 1055.4041\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.9396 - mse: 294.6080\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.4910 - mse: 211.0175\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 8.8214 - mse: 178.0057\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.4782 - mse: 800.3290\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.8497 - mse: 282.1823\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.8419 - mse: 294.2351\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.3787 - mse: 274.9174\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 31.0326 - mse: 1354.2535\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.6989 - mse: 251.5774\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.7343 - mse: 927.1674\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.8637 - mse: 259.5757\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.1562 - mse: 249.2289\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.4313 - mse: 332.9313\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 32.9634 - mse: 1524.9326\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.1986 - mse: 282.6111\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.9160 - mse: 373.9595\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.0813 - mse: 534.7462\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 34.1370 - mse: 1784.8190\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.2431 - mse: 108.9753\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 21.7224 - mse: 706.9938\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 19.8383 - mse: 567.9308\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0707 - mse: 288.5107\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.3356 - mse: 622.0129\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.8995 - mse: 218.7732\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.7801 - mse: 77.2141\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.8593 - mse: 827.6569\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 29.5703 - mse: 1268.8030\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.2665 - mse: 106.7797\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.0686 - mse: 48.7766\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 34.7233 - mse: 1829.0505\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3412 - mse: 100.4985\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 9.1538 - mse: 127.9614\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.8544 - mse: 205.3397\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 8.9199 - mse: 140.1065\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.6868 - mse: 141.6686\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 25.0877 - mse: 921.4108\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.1512 - mse: 280.6262\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.8736 - mse: 213.8290\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.1561 - mse: 286.3854\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.7279 - mse: 319.1890\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 17.0633 - mse: 465.9789\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 19.3443 - mse: 534.3582\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.6960 - mse: 385.1133\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.4719 - mse: 217.2453\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.3436 - mse: 357.3977\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 22.1107 - mse: 753.9279\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7105 - mse: 82.4598\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.6118 - mse: 273.1009\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 19.1051 - mse: 571.1633\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 26.4671 - mse: 1021.8913\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0792 - mse: 173.8795\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.1517 - mse: 40.2208\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.8077 - mse: 512.3073\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.3263 - mse: 261.1062\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.4041 - mse: 326.8082\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.4075 - mse: 339.5023\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.7419 - mse: 320.2950\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24.9778 - mse: 883.0524\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 19.1388 - mse: 519.4136\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.5711 - mse: 282.2755\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.2242 - mse: 580.6855\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.9351 - mse: 1007.3092\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.5935 - mse: 351.5407\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.6526 - mse: 281.9190\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24.2780 - mse: 838.5664\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 16.2797 - mse: 391.6419\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.4338 - mse: 210.6253\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.3794 - mse: 67.7010\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.7626 - mse: 475.4222\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.0234 - mse: 261.4665\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.0807 - mse: 679.6835\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 30.2959 - mse: 1416.4515\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.8325 - mse: 241.5135\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.7097 - mse: 281.2069\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.4597 - mse: 706.0001\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.3104 - mse: 272.7270\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7989 - mse: 157.4369\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.2027 - mse: 243.5208\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.8896 - mse: 931.5195\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.0039 - mse: 348.6295\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.7948 - mse: 236.1382\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.8623 - mse: 372.9518\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 24.7144 - mse: 847.3391\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.5656 - mse: 454.6822\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.7163 - mse: 189.0647\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 24.9130 - mse: 877.7565\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.1225 - mse: 405.5091\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4654 - mse: 81.1299\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.5441 - mse: 643.0438\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.6520 - mse: 81.7296\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.8155 - mse: 308.8632\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11.7674 - mse: 222.2961\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.5095 - mse: 219.1998\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.0563 - mse: 268.6877\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6051 - mse: 90.6652\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.8279 - mse: 344.4601\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 17.9457 - mse: 468.9531\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7130 - mse: 251.5827\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 29.1169 - mse: 1233.7069\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.2796 - mse: 229.0432\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.6930 - mse: 274.3319\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 33.5526 - mse: 1559.1388\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.9204 - mse: 288.0503\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.3505 - mse: 473.9809\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 22.0311 - mse: 735.8329\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24.2373 - mse: 831.1022\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.5245 - mse: 217.6531\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.7614 - mse: 307.9101\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.7724 - mse: 501.6465\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.6770 - mse: 52.1622\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5166 - mse: 234.8883\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.1783 - mse: 281.9757\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.9440 - mse: 436.4635\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.3605 - mse: 311.0165\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 30.7707 - mse: 1342.0830\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.4148 - mse: 195.2593\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 27.6925 - mse: 1071.5121\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.8312 - mse: 187.7357\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.6270 - mse: 289.7391\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.7890 - mse: 483.4676\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.0619 - mse: 269.8936\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 26.0022 - mse: 975.4777\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.7843 - mse: 326.8501\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.0183 - mse: 263.0505\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.3071 - mse: 244.8637\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 29.5312 - mse: 1218.3016\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.4591 - mse: 22.1120\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.1962 - mse: 351.4818\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.7925 - mse: 649.1941\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 30.6246 - mse: 1432.6101\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1070 - mse: 236.7167\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.9014 - mse: 279.7796\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 3.5627 - mse: 18.5622\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 42.0638 - mse: 2705.0415\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.6053 - mse: 46.6731\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.4567 - mse: 529.2546\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 41.5628 - mse: 2717.0261\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.5718 - mse: 440.8024\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.2544 - mse: 243.4644\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 29.3734 - mse: 1206.4413\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.6482 - mse: 74.7709\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.8072 - mse: 183.1378\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 18.4698 - mse: 530.9240\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.3174 - mse: 405.9012\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.1087 - mse: 353.1798\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.6300 - mse: 639.3577\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 34.8879 - mse: 1855.5242\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.6770 - mse: 303.0331\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3646 - mse: 109.6690\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.4212 - mse: 68.4842\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 31.2173 - mse: 1437.8864\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.2965 - mse: 237.3114\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.9182 - mse: 249.3195\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.9857 - mse: 860.0618\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.6227 - mse: 542.8209\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.7966 - mse: 50.6428\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.0276 - mse: 225.7408\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.6991 - mse: 252.4148\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.8986 - mse: 242.5773\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.0246 - mse: 534.5609\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 22.6500 - mse: 748.7131\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.5478 - mse: 115.9362\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.4578 - mse: 279.1796\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6532d4e0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make and plot predictions for model_3\n",
        "y_preds_3 = model_3.predict(X_test)  \n",
        "plot_predictions(predictions = y_preds_3) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "OgAWnqZrv2Zh",
        "outputId": "1f600011-7832-4d2f-99e9-c5705c249915"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_3 evaluation metrics\n",
        "mae_3 = mae(y_test, tf.squeeze(y_preds_3))\n",
        "mse_3 = mse(y_test, tf.squeeze(y_preds_3)) \n",
        "mae_3, mse_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKe40UqrwAd3",
        "outputId": "90706371-53be-442c-9a5a-da8c3a30d5e0"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=float32, numpy=68.149315>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=4729.35>)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This last is an example of how tweaking some hyperparameters you think might lead to a better result, do not lead to a better result!\n",
        "# This is model OVERFITTING!\n",
        "# Essentially means that the model has learned the training data too well and it does not generalize well to data it has not seen before!"
      ],
      "metadata": {
        "id": "W9CdCNz4wHln"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important note**: You want to start with small experiments (small models) and make sure they work and then increase their scale when necessary. (Start small, build up, add complexity when needed). \n",
        "\n",
        "Start small, build up, add complexity when needed."
      ],
      "metadata": {
        "id": "OhzujYjSyKPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing the results of our experiments\n",
        "\n",
        "Machine learning practictioner's motto -> \"Experiment, experiment, experiment\". But comparing to see what works and what does not!\n",
        "\n",
        "We've run a few experiments, let's compare the results. \n",
        "\n",
        "Basically, compare the experiments. Discard what does not work, continue with the ones that work and keep experimenting."
      ],
      "metadata": {
        "id": "ljTuKhUmxlaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the experiment results in a structured way\n",
        "# Let's compare our model's results using a pandas DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "model_results = [\n",
        "    [\"model_1\", mae_1, mse_1],\n",
        "    [\"model_2\", mae_2, mse_2],\n",
        "    [\"model_3\", mae_3, mse_3]\n",
        "]\n",
        "\n",
        "all_results = pd.DataFrame(model_results, columns=[\"Model\", \"MAE\", \"MSE\"])\n",
        "all_results  # worrks but is harrd to read"
      ],
      "metadata": {
        "id": "OB1YbWfOx7Mv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "1a42b65e-b16f-495f-ea32-9dc45154f6b6"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Model                                            MAE  \\\n",
              "0  model_1  tf.Tensor(18.745327, shape=(), dtype=float32)   \n",
              "1  model_2  tf.Tensor(3.1969407, shape=(), dtype=float32)   \n",
              "2  model_3  tf.Tensor(68.149315, shape=(), dtype=float32)   \n",
              "\n",
              "                                             MSE  \n",
              "0  tf.Tensor(353.57336, shape=(), dtype=float32)  \n",
              "1  tf.Tensor(13.070143, shape=(), dtype=float32)  \n",
              "2    tf.Tensor(4729.35, shape=(), dtype=float32)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09fa5c1d-1365-482b-b319-23924d5b2512\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model_1</td>\n",
              "      <td>tf.Tensor(18.745327, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(353.57336, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>model_2</td>\n",
              "      <td>tf.Tensor(3.1969407, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(13.070143, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>model_3</td>\n",
              "      <td>tf.Tensor(68.149315, shape=(), dtype=float32)</td>\n",
              "      <td>tf.Tensor(4729.35, shape=(), dtype=float32)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09fa5c1d-1365-482b-b319-23924d5b2512')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-09fa5c1d-1365-482b-b319-23924d5b2512 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-09fa5c1d-1365-482b-b319-23924d5b2512');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_results = [\n",
        "    [\"model_1\", mae_1.numpy(), mse_1.numpy()],\n",
        "    [\"model_2\", mae_2.numpy(), mse_2.numpy()],\n",
        "    [\"model_3\", mae_3.numpy(), mse_3.numpy()]\n",
        "]\n",
        "\n",
        "all_results = pd.DataFrame(model_results, columns=[\"Model\", \"MAE\", \"MSE\"])\n",
        "all_results  # worrks but is harrd to read"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "5t1lQcgSoyWP",
        "outputId": "452a0d71-b8be-48be-b28c-5aa0fd0277ca"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Model        MAE          MSE\n",
              "0  model_1  18.745327   353.573364\n",
              "1  model_2   3.196941    13.070143\n",
              "2  model_3  68.149315  4729.350098"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7360bdd7-6e08-4fac-a5f0-ce263327d1d2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>MAE</th>\n",
              "      <th>MSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model_1</td>\n",
              "      <td>18.745327</td>\n",
              "      <td>353.573364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>model_2</td>\n",
              "      <td>3.196941</td>\n",
              "      <td>13.070143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>model_3</td>\n",
              "      <td>68.149315</td>\n",
              "      <td>4729.350098</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7360bdd7-6e08-4fac-a5f0-ce263327d1d2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7360bdd7-6e08-4fac-a5f0-ce263327d1d2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7360bdd7-6e08-4fac-a5f0-ce263327d1d2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like `model_2` performed the best..."
      ],
      "metadata": {
        "id": "sAE_O3Ugpq2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2 performed the best\n",
        "model_2.summary()   # 2 layers, fit for 100 epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdMw4EEupKlQ",
        "outputId": "0bc77826-9d9d-4365-9ecf-2a2363637b92"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 10)                20        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** One of your main goals should be to minimize the time between your experiments, that is why is important to start small! The more experiments you do, the more things you'll figure out which do not work and in turn, then when you know what does not work, you will get closer to figuring out what does work. Remember the ML practictioner's mott: \"experiment, experiment, experiment\"."
      ],
      "metadata": {
        "id": "lHawTWYppwzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing differrent models is what machine learning modelling is all about.\n",
        "# Trying many different combinations of models and seeing which one performs best and what does not\n",
        "# Each experiment is to figure out what doesnt work and what works"
      ],
      "metadata": {
        "id": "JvdknaEvpSbA"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tracking your experiments\n",
        "\n",
        "One really good habit in machine learning modeling is to track the results of your experiments.\n",
        "\n",
        "And when doing so, it can be tedious if you are running lots of experiments.\n",
        "\n",
        "Luckily, there are tools to help us!\n",
        "\n",
        "**Resource:** As you build more models, you will want to look into using:\n",
        "\n",
        "* **TensorBoard** - a component of the TensorFlow library to help track modeling experiments (we will see this one later).\n",
        "* **Weights & Biases** - a tool for tracking all kinds of machine learning experiments (plugs straight into TensorBoard). https://wandb.com "
      ],
      "metadata": {
        "id": "2Y3cfc3QposX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving our models\n",
        "\n",
        "Saving our models allows us to use them outside of Google Colab (or wherever they were trained) such as in a web application or a mobile app.\n",
        "\n",
        "Theree are two main formats we can save our model's to: \n",
        "\n",
        "1. The SavedModel format. (default one in TF)\n",
        "2. The HDF5 format.\n",
        "\n",
        "They both can be saved using the same function in TF. Which saves:\n",
        "\n",
        "    * Model architecturre, allowing to re-instantiate the model.\n",
        "    * Model weights.\n",
        "    * State of the optimizer, allowing to resume training exactly where you left off."
      ],
      "metadata": {
        "id": "vTsxBUrUqlhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model using the SaveModel format (TF related and creates multiple files; inside a folder)\n",
        "model_2.save(\"best_model_SavedModel_format\")  # good format if TF will be used consistently for the model"
      ],
      "metadata": {
        "id": "YGyycDZrrdsP"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model using the HDF5 format (HDF5 standard, universal data format and a single file)\n",
        "# Adding .H5 saves the model in HDF5 format.\n",
        "model_2.save(\"best_model_HDF5_fomat.h5\")  # better format if the model is going to be used outside of TF"
      ],
      "metadata": {
        "id": "OfRKKSFRzIEh"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the model has been saved correctly -> Loading it! And reevaluate it!"
      ],
      "metadata": {
        "id": "DzrE4RhGz16W"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading in a saved model"
      ],
      "metadata": {
        "id": "FGBC5JYJ0eCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Restore models using both formats\n",
        "\n",
        "# Load in the SavedModel format model\n",
        "loaded_SavedModel_format = tf.keras.models.load_model(\"/content/best_model_SavedModel_format\")\n",
        "\n",
        "loaded_SavedModel_format.summary()  # same as model 2 above!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPkYjaMA0hMU",
        "outputId": "51bed6e8-ee15-4715-c1f2-1d8ea6c89851"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 10)                20        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZPXnIQH07ib",
        "outputId": "55fa8e8e-fe81-4fa1-d892-279ea64c878e"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 10)                20        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model is the same, what about the weights (patterns the model has learned)?\n",
        "# Let's make some predictions and compare!\n",
        "\n",
        "# Compare model_2 predictions with SavedModel format model predictions\n",
        "\n",
        "model_2_preds = model_2.predict(X_test)\n",
        "loaded_SavedModel_format_preds = loaded_SavedModel_format(X_test)\n",
        "\n",
        "model_2_preds == loaded_SavedModel_format_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cteciRsX0_v9",
        "outputId": "853a24bd-99b9-4759-98c9-97cb131a6af9"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 1), dtype=bool, numpy=\n",
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extra check, compare the mae of model_2_preds and loaded_SavedModel_preds\n",
        "mae(y_true = y_test, y_pred = model_2_preds) == mae(y_true = y_test, y_pred = loaded_SavedModel_format_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y73XNBy91bS7",
        "outputId": "da2bae01-ff31-4361-bf1b-65f94da936e8"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=bool, numpy=\n",
              "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True])>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The same!!!!!!\n",
        "# model_2_preds.squeeze(), loaded_SavedModel_format_preds.squeeze()"
      ],
      "metadata": {
        "id": "UqlEu81e1tmp"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in a model using the .h5 format\n",
        "loaded_h5_model = tf.keras.models.load_model('/content/best_model_HDF5_fomat.h5')\n",
        "\n",
        "loaded_h5_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIz-B6aT18y3",
        "outputId": "794f323d-2b8c-4a3c-d7ac-40af5085510c"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 10)                20        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model looks the same...\n",
        "# check to see if loaded .h5 model predictions match model_2\n",
        "\n",
        "model_2_preds = model_2.predict(X_test)\n",
        "loaded_h5_model_preds = loaded_h5_model(X_test)\n",
        "\n",
        "model_2_preds == loaded_h5_model_preds   # always check if the model is well imported, does same predictions! It could be done using a function coded for it!!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fDRAs9U2DeN",
        "outputId": "7ad4e800-0652-4f69-f020-cf191d22218f"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 1), dtype=bool, numpy=\n",
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download a model (or any other file) from Google Colab\n",
        "\n",
        "If you want to download your files from Google Colab:\n",
        "\n",
        "1. You can go to the \"files\" tab and right click on the file you are after (or the three dots) and click \"download\".\n",
        "2. Use code (see the cell below).\n",
        "3. Save it to Google Drive by connecting Google Drive and copying it there (see 2nd code cell below)."
      ],
      "metadata": {
        "id": "eLsBwhms3aHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a file from Google Colab\n",
        "from google.colab import files\n",
        "\n",
        "files.download(\"/content/best_model_HDF5_fomat.h5\")  # it downloads it!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-RxnaEwy3iSB",
        "outputId": "6aa14d45-5bc4-4bec-8bf0-becd95d2c927"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9bae1734-9589-4a36-98b1-829e153052eb\", \"best_model_HDF5_fomat.h5\", 17872)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save a file from Google Colab to Google Drive (requires mounting Google Drive), using the copy command\n",
        "!cp /content/best_model_HDF5_fomat.h5 /content/drive/MyDrive/<folder_here>  # copying it to the mounted drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvD1mCOY4BWM",
        "outputId": "b7d547ba-ceba-404e-e799-e80261be8c53"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 0: `cp /content/best_model_HDF5_fomat.h5 /content/drive/MyDrive/<folder_here>  # copying it to the mounted drive'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/<folder_here> # should show the file there"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAUx7X9Q4jc2",
        "outputId": "0b0e7b19-9076-4ea2-f06b-56e20fd8420e"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 0: `ls /content/drive/MyDrive/<folder_here> # should show the file there'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A larger example\n",
        "\n",
        "Using more complex data :)"
      ],
      "metadata": {
        "id": "KU4i1VKZ4qUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We are going to use Medical Cost Personal Datasets from Kaggle\n",
        "# Kaggle has very good example datasets!! \n",
        "\n",
        "# DATASET LINK --> https://www.kaggle.com/datasets/mirichoi0218/insurance\n",
        "\n",
        "# Goal is to use the features (age, sex, bmi, etc.) to predict someone's individual costs build by a health insurance.\n",
        "# So it is a regression problem, we use the features to forecast a number!\n",
        "\n",
        "# Getting the data from GitHub repository and raw data link -> https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\n"
      ],
      "metadata": {
        "id": "piMRV0Co5w8s"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "AlaeCfHn530f"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in the insurance dataset\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "# the function will get it and import it directly using the url\n",
        "\n",
        "insurance # shape is 1338 rows and 6 features, and the target variable which is charges\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zkkK4FsI60EM",
        "outputId": "cdb6f9c4-027a-43be-f226-22b38ae43a24"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cf159d1-2b08-4465-8eb0-969f2ef4d5c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cf159d1-2b08-4465-8eb0-969f2ef4d5c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5cf159d1-2b08-4465-8eb0-969f2ef4d5c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5cf159d1-2b08-4465-8eb0-969f2ef4d5c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Goal, learn the relationships between the features and the target variable, charges.\n",
        "# Regression problem!! Relation between the dependent variable (outcome variable, target) and the independent variables (features, predictors, covariates)"
      ],
      "metadata": {
        "id": "24M-rJi_7CgK"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FIRST STEP is to make everything numeric datatype! (convert strings, binary, etc.)\n",
        "insurance[\"sex\"], insurance[\"age\"], insurance[\"region\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kHiYW217nu0",
        "outputId": "c07d9a22-4e47-419f-ee43-a426e1381665"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0       female\n",
              " 1         male\n",
              " 2         male\n",
              " 3         male\n",
              " 4         male\n",
              "          ...  \n",
              " 1333      male\n",
              " 1334    female\n",
              " 1335    female\n",
              " 1336    female\n",
              " 1337    female\n",
              " Name: sex, Length: 1338, dtype: object, 0       19\n",
              " 1       18\n",
              " 2       28\n",
              " 3       33\n",
              " 4       32\n",
              "         ..\n",
              " 1333    50\n",
              " 1334    18\n",
              " 1335    18\n",
              " 1336    21\n",
              " 1337    61\n",
              " Name: age, Length: 1338, dtype: int64, 0       southwest\n",
              " 1       southeast\n",
              " 2       southeast\n",
              " 3       northwest\n",
              " 4       northwest\n",
              "           ...    \n",
              " 1333    northwest\n",
              " 1334    northeast\n",
              " 1335    southeast\n",
              " 1336    southwest\n",
              " 1337    northwest\n",
              " Name: region, Length: 1338, dtype: object)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We have to change everything non-numeric to numeric before we can pass it to a deep neural network or a ML model. \n",
        "# How?\n",
        "# Creating the NUMERICAL ENCODING before passing the values to the DL model"
      ],
      "metadata": {
        "id": "9vZqIpeh730j"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's use ONE HOT encoding, one of the simplest methods to turn categorical values into numerical variables\n",
        "# We could do it manually, creating the dummy variables ourselves, but we are going to use pandas get_dummies function!\n",
        "\n",
        "# get_dummies from Pandas allows the creation of ONE HOT encoding for categorical variables\n",
        "\n",
        "# One hot encoding creates dummy/indicator variables to encode the categorical data!!"
      ],
      "metadata": {
        "id": "biYRyaC28PMt"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try one-hot encode our DataFrame so it is all numbers!\n",
        "pd.get_dummies(insurance)  # it creates all the dummy variables automatically for the categorical variables to numeric encoding!!!!!!!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "EiFlbvxM9IAx",
        "outputId": "5d1999df-9341-4fcc-8fc2-534cdf949043"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
              "0      19  27.900         0  16884.92400           1         0          0   \n",
              "1      18  33.770         1   1725.55230           0         1          1   \n",
              "2      28  33.000         3   4449.46200           0         1          1   \n",
              "3      33  22.705         0  21984.47061           0         1          1   \n",
              "4      32  28.880         0   3866.85520           0         1          1   \n",
              "...   ...     ...       ...          ...         ...       ...        ...   \n",
              "1333   50  30.970         3  10600.54830           0         1          1   \n",
              "1334   18  31.920         0   2205.98080           1         0          1   \n",
              "1335   18  36.850         0   1629.83350           1         0          1   \n",
              "1336   21  25.800         0   2007.94500           1         0          1   \n",
              "1337   61  29.070         0  29141.36030           1         0          0   \n",
              "\n",
              "      smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
              "0              1                 0                 0                 0   \n",
              "1              0                 0                 0                 1   \n",
              "2              0                 0                 0                 1   \n",
              "3              0                 0                 1                 0   \n",
              "4              0                 0                 1                 0   \n",
              "...          ...               ...               ...               ...   \n",
              "1333           0                 0                 1                 0   \n",
              "1334           0                 1                 0                 0   \n",
              "1335           0                 0                 0                 1   \n",
              "1336           0                 0                 0                 0   \n",
              "1337           1                 0                 1                 0   \n",
              "\n",
              "      region_southwest  \n",
              "0                    1  \n",
              "1                    0  \n",
              "2                    0  \n",
              "3                    0  \n",
              "4                    0  \n",
              "...                ...  \n",
              "1333                 0  \n",
              "1334                 0  \n",
              "1335                 0  \n",
              "1336                 1  \n",
              "1337                 0  \n",
              "\n",
              "[1338 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f64473dd-e971-439e-a649-2fd94797c8f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>10600.54830</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>2205.98080</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>1629.83350</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>2007.94500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>29141.36030</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows × 12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f64473dd-e971-439e-a649-2fd94797c8f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f64473dd-e971-439e-a649-2fd94797c8f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f64473dd-e971-439e-a649-2fd94797c8f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving it into a variable\n",
        "insurance_one_hot = pd.get_dummies(insurance)\n",
        "insurance_one_hot.head()  # check the first rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "FuByZKi19YEx",
        "outputId": "7b2f1953-8e0e-4cd5-c2be-3bb96d43d6f3"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
              "0   19  27.900         0  16884.92400           1         0          0   \n",
              "1   18  33.770         1   1725.55230           0         1          1   \n",
              "2   28  33.000         3   4449.46200           0         1          1   \n",
              "3   33  22.705         0  21984.47061           0         1          1   \n",
              "4   32  28.880         0   3866.85520           0         1          1   \n",
              "\n",
              "   smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
              "0           1                 0                 0                 0   \n",
              "1           0                 0                 0                 1   \n",
              "2           0                 0                 0                 1   \n",
              "3           0                 0                 1                 0   \n",
              "4           0                 0                 1                 0   \n",
              "\n",
              "   region_southwest  \n",
              "0                 1  \n",
              "1                 0  \n",
              "2                 0  \n",
              "3                 0  \n",
              "4                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d406b0f2-3283-420f-89d3-72b15166d775\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d406b0f2-3283-420f-89d3-72b15166d775')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d406b0f2-3283-420f-89d3-72b15166d775 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d406b0f2-3283-420f-89d3-72b15166d775');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NEXT STEPS\n",
        "# 1. Create X & y values (features and labels)\n",
        "# 2. Create training and test sets\n",
        "# 3. Build a neural network (sort of like model_2 above)"
      ],
      "metadata": {
        "id": "Y4c94XaA9lcO"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create X & y values (features and labels)\n",
        "X = insurance_one_hot.drop(\"charges\", axis=1)  #getting the features, dropping the target\n",
        "y = insurance_one_hot[\"charges\"]  # getting the target column alone"
      ],
      "metadata": {
        "id": "iVJdSyEM-Cdg"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View X\n",
        "X.head()   # always visualize, visualize, visualize when in doubt!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "OAkwJU67-Vdy",
        "outputId": "4f2b3194-8fd5-44f7-ed35-687a0e55d599"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
              "0   19  27.900         0           1         0          0           1   \n",
              "1   18  33.770         1           0         1          1           0   \n",
              "2   28  33.000         3           0         1          1           0   \n",
              "3   33  22.705         0           0         1          1           0   \n",
              "4   32  28.880         0           0         1          1           0   \n",
              "\n",
              "   region_northeast  region_northwest  region_southeast  region_southwest  \n",
              "0                 0                 0                 0                 1  \n",
              "1                 0                 0                 1                 0  \n",
              "2                 0                 0                 1                 0  \n",
              "3                 0                 1                 0                 0  \n",
              "4                 0                 1                 0                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db8eba0c-3240-4a29-aefd-5458426c6a2a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db8eba0c-3240-4a29-aefd-5458426c6a2a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db8eba0c-3240-4a29-aefd-5458426c6a2a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db8eba0c-3240-4a29-aefd-5458426c6a2a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View y\n",
        "y.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7qXsMMc-Y1N",
        "outputId": "817e8bf9-e251-4d4e-9339-34c7fc0b84e4"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    16884.92400\n",
              "1     1725.55230\n",
              "2     4449.46200\n",
              "3    21984.47061\n",
              "4     3866.85520\n",
              "Name: charges, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and test sets using a much better function that randomizes the selection, using scikit-learrn train/test split function\n",
        "# Creating these sets is one of the most important things in ML\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  #80-20 split is very common\n",
        "# random_state for reproducibility to get the same split every time, otherwise would change\n",
        "len(X), len(X_train), len(X_test)   # randomly shuffled split, 80% training, 20% testing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0FsMGdM-aTK",
        "outputId": "cea5085a-28f9-4cce-957b-02d422bc9b35"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1338, 1070, 268)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBXTVz1e_A2s",
        "outputId": "fc922b83-c222-4a1f-a085-733cfb25b53f"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(      age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
              " 560    46  19.950         2           1         0          1           0   \n",
              " 1285   47  24.320         0           1         0          1           0   \n",
              " 1142   52  24.860         0           1         0          1           0   \n",
              " 969    39  34.320         5           1         0          1           0   \n",
              " 486    54  21.470         3           1         0          1           0   \n",
              " ...   ...     ...       ...         ...       ...        ...         ...   \n",
              " 1095   18  31.350         4           1         0          1           0   \n",
              " 1130   39  23.870         5           1         0          1           0   \n",
              " 1294   58  25.175         0           0         1          1           0   \n",
              " 860    37  47.600         2           1         0          0           1   \n",
              " 1126   55  29.900         0           0         1          1           0   \n",
              " \n",
              "       region_northeast  region_northwest  region_southeast  region_southwest  \n",
              " 560                  0                 1                 0                 0  \n",
              " 1285                 1                 0                 0                 0  \n",
              " 1142                 0                 0                 1                 0  \n",
              " 969                  0                 0                 1                 0  \n",
              " 486                  0                 1                 0                 0  \n",
              " ...                ...               ...               ...               ...  \n",
              " 1095                 1                 0                 0                 0  \n",
              " 1130                 0                 0                 1                 0  \n",
              " 1294                 1                 0                 0                 0  \n",
              " 860                  0                 0                 0                 1  \n",
              " 1126                 0                 0                 0                 1  \n",
              " \n",
              " [1070 rows x 11 columns],\n",
              "       age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
              " 764    45  25.175         2           1         0          1           0   \n",
              " 887    36  30.020         0           1         0          1           0   \n",
              " 890    64  26.885         0           1         0          0           1   \n",
              " 1293   46  25.745         3           0         1          1           0   \n",
              " 259    19  31.920         0           0         1          0           1   \n",
              " ...   ...     ...       ...         ...       ...        ...         ...   \n",
              " 109    63  35.090         0           0         1          0           1   \n",
              " 575    58  27.170         0           1         0          1           0   \n",
              " 535    38  28.025         1           0         1          1           0   \n",
              " 543    54  47.410         0           1         0          0           1   \n",
              " 846    51  34.200         1           1         0          1           0   \n",
              " \n",
              "       region_northeast  region_northwest  region_southeast  region_southwest  \n",
              " 764                  1                 0                 0                 0  \n",
              " 887                  0                 1                 0                 0  \n",
              " 890                  0                 1                 0                 0  \n",
              " 1293                 0                 1                 0                 0  \n",
              " 259                  0                 1                 0                 0  \n",
              " ...                ...               ...               ...               ...  \n",
              " 109                  0                 0                 1                 0  \n",
              " 575                  0                 1                 0                 0  \n",
              " 535                  1                 0                 0                 0  \n",
              " 543                  0                 0                 1                 0  \n",
              " 846                  0                 0                 0                 1  \n",
              " \n",
              " [268 rows x 11 columns],\n",
              " 560      9193.83850\n",
              " 1285     8534.67180\n",
              " 1142    27117.99378\n",
              " 969      8596.82780\n",
              " 486     12475.35130\n",
              "            ...     \n",
              " 1095     4561.18850\n",
              " 1130     8582.30230\n",
              " 1294    11931.12525\n",
              " 860     46113.51100\n",
              " 1126    10214.63600\n",
              " Name: charges, Length: 1070, dtype: float64,\n",
              " 764      9095.06825\n",
              " 887      5272.17580\n",
              " 890     29330.98315\n",
              " 1293     9301.89355\n",
              " 259     33750.29180\n",
              "            ...     \n",
              " 109     47055.53210\n",
              " 575     12222.89830\n",
              " 535      6067.12675\n",
              " 543     63770.42801\n",
              " 846      9872.70100\n",
              " Name: charges, Length: 268, dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Build a neural network (sort of like model_2 above) to take in X_train and y_train and learn the relationships between the two.\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model \n",
        "insurance_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model.compile(loss=tf.keras.losses.mae,\n",
        "                        optimizer=tf.keras.optimizers.SGD(),\n",
        "                        metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "insurance_model.fit(X_train, y_train, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXid5m_i_mJ1",
        "outputId": "e89c627d-63bf-4548-8aa0-eba3dcce09b0"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 1s 2ms/step - loss: 8637.1006 - mae: 8637.1006\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7886.7759 - mae: 7886.7759\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7558.1470 - mae: 7558.1470\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7792.0225 - mae: 7792.0225\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7748.3887 - mae: 7748.3887\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7595.3940 - mae: 7595.3940\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7589.9844 - mae: 7589.9844\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7698.5576 - mae: 7698.5576\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7496.7778 - mae: 7496.7778\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7493.1743 - mae: 7493.1743\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7769.7305 - mae: 7769.7305\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7706.9028 - mae: 7706.9028\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7687.7231 - mae: 7687.7231\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7689.9004 - mae: 7689.9004\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7393.5322 - mae: 7393.5322\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7780.6987 - mae: 7780.6987\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7578.5098 - mae: 7578.5098\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7750.8354 - mae: 7750.8354\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7739.2144 - mae: 7739.2144\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7875.0654 - mae: 7875.0654\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7466.6768 - mae: 7466.6768\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7941.2329 - mae: 7941.2329\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7640.2734 - mae: 7640.2734\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7539.2671 - mae: 7539.2671\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7619.9653 - mae: 7619.9653\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7644.1714 - mae: 7644.1714\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7709.0371 - mae: 7709.0371\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7366.8662 - mae: 7366.8662\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7444.3154 - mae: 7444.3154\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7616.4082 - mae: 7616.4082\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7686.3848 - mae: 7686.3848\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7548.0977 - mae: 7548.0977\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7501.5532 - mae: 7501.5532\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7363.4160 - mae: 7363.4160\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7295.4478 - mae: 7295.4478\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7569.8804 - mae: 7569.8804\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7548.1997 - mae: 7548.1997\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7424.3975 - mae: 7424.3975\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7529.7739 - mae: 7529.7739\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7467.3232 - mae: 7467.3232\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7635.9292 - mae: 7635.9292\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7536.8398 - mae: 7536.8398\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7616.5859 - mae: 7616.5859\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7439.4941 - mae: 7439.4941\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7538.0142 - mae: 7538.0142\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7415.1470 - mae: 7415.1470\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7420.6938 - mae: 7420.6938\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7509.9839 - mae: 7509.9839\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7541.1133 - mae: 7541.1133\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7467.8643 - mae: 7467.8643\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7389.3560 - mae: 7389.3560\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7499.7759 - mae: 7499.7759\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7523.9282 - mae: 7523.9282\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7243.3115 - mae: 7243.3115\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7429.5864 - mae: 7429.5864\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7313.3999 - mae: 7313.3999\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7526.3877 - mae: 7526.3877\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7542.2666 - mae: 7542.2666\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7576.9277 - mae: 7576.9277\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7546.4058 - mae: 7546.4058\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7351.2271 - mae: 7351.2271\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7302.1436 - mae: 7302.1436\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7393.0874 - mae: 7393.0874\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7442.2881 - mae: 7442.2881\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7492.6782 - mae: 7492.6782\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7561.9165 - mae: 7561.9165\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7340.5137 - mae: 7340.5137\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7496.0840 - mae: 7496.0840\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7617.0303 - mae: 7617.0303\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7641.1948 - mae: 7641.1948\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7084.2744 - mae: 7084.2744\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7240.4902 - mae: 7240.4902\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7283.4888 - mae: 7283.4888\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7335.5088 - mae: 7335.5088\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7275.6396 - mae: 7275.6396\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7313.1860 - mae: 7313.1860\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7485.7588 - mae: 7485.7588\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7352.2803 - mae: 7352.2803\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7520.5703 - mae: 7520.5703\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7279.3779 - mae: 7279.3779\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7273.8477 - mae: 7273.8477\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7176.5215 - mae: 7176.5215\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7425.6289 - mae: 7425.6289\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7403.1294 - mae: 7403.1294\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7356.0088 - mae: 7356.0088\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7484.7266 - mae: 7484.7266\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7217.6074 - mae: 7217.6074\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7261.0000 - mae: 7261.0000\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7134.1562 - mae: 7134.1562\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7083.4355 - mae: 7083.4355\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7254.1782 - mae: 7254.1782\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7268.7461 - mae: 7268.7461\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7470.5215 - mae: 7470.5215\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7210.9536 - mae: 7210.9536\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7395.6816 - mae: 7395.6816\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7328.0884 - mae: 7328.0884\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7230.4380 - mae: 7230.4380\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7261.3936 - mae: 7261.3936\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7342.5684 - mae: 7342.5684\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7106.1714 - mae: 7106.1714\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f65323a85d0>"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We did not even need to reformat the inputs/targets into tensors\n",
        "# That is because Pandas is built on top of numpy! So it is actually using numpy arrays in the back.\n",
        "# So TF knows how to handle numpy arrays and, consequently, pandas!"
      ],
      "metadata": {
        "id": "rb4zFBGoAlb-"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the results of the insurance model on the test data\n",
        "insurance_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqnTiDfbBSve",
        "outputId": "e019d760-099b-48de-ab66-355743e2c5d7"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 7023.3291 - mae: 7023.3291\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7023.3291015625, 7023.3291015625]"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# So the performance on the testing set is slightly better than in the training set, cool!!\n",
        "\n",
        "# Remember than MAE means that, on average, our model is wrong about 7000 per prediction!\n",
        "# So it is that large, it is significant compared to the other values in our dataset?\n",
        "\n",
        "y_train.median(), y_train.mean()  # with these averages, making an error of 7000 off on average is quite a lot!!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWuB1SY8BbKs",
        "outputId": "3281d0c1-77fa-4f6d-c141-c6e36d92336e"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9575.4421, 13346.089736364485)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Right now it looks like our model is not performing too well...let's try and improve it!\n",
        "\n",
        "To (try) improve our model, we will run 2 experiments:\n",
        "1. Add an extra layer with more hidden units\n",
        "2. Train for longer the model above\n",
        "3. (insert your own experiment here)"
      ],
      "metadata": {
        "id": "3F2jigWOBviC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1.  Create the model\n",
        "insurance_model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),   # extra layer added, more potential to learn in theory, more complex model\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.SGD(),\n",
        "                          metrics=[\"mae\"])\n",
        "#\n",
        "# 3. Fit the model\n",
        "insurance_model_2.fit(X_train, y_train, epochs=100, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR_aBwHjCMZo",
        "outputId": "103e1c1b-3743-4219-cef7-e686c9b926c7"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan           \n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: nan - mae: nan\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6532725910>"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What happens? Why the loss and mae are nan?\n",
        "# Let's troubleshoot!\n",
        "\n",
        "# The addition of the layer made the model too complex maybe four our dataset that is not so large enough to teach it anything\n",
        "# Let's alter something about the compile step, changing the optimizer"
      ],
      "metadata": {
        "id": "_AVPFVHlEs1Z"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1.  Create the model\n",
        "insurance_model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),   # extra layer added, more potential to learn in theory, more complex model\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(),  #ADAM is a good one to go!!\n",
        "                          metrics=[\"mae\"])\n",
        "#\n",
        "# 3. Fit the model\n",
        "insurance_model_2.fit(X_train, y_train, epochs=100, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyV5KTJPGJdn",
        "outputId": "c0ff29d3-09e4-4025-b830-88f5b101fc84"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13273.1602 - mae: 13273.1602\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13104.4297 - mae: 13104.4297\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12749.5420 - mae: 12749.5420\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12055.7500 - mae: 12055.7500\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10905.8154 - mae: 10905.8154\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 9457.7217 - mae: 9457.7217\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8147.6543 - mae: 8147.6543\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7528.8413 - mae: 7528.8413\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7429.1528 - mae: 7429.1528\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7409.0811 - mae: 7409.0811\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7390.8042 - mae: 7390.8042\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7368.9170 - mae: 7368.9170\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7348.5190 - mae: 7348.5190\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7326.4893 - mae: 7326.4893\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7307.5811 - mae: 7307.5811\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7285.7734 - mae: 7285.7734\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7265.7104 - mae: 7265.7104\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7242.5488 - mae: 7242.5488\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7220.5068 - mae: 7220.5068\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7197.1978 - mae: 7197.1978\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7179.0195 - mae: 7179.0195\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7151.2104 - mae: 7151.2104\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7126.4639 - mae: 7126.4639\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7101.9199 - mae: 7101.9199\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7084.3379 - mae: 7084.3379\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7052.3291 - mae: 7052.3291\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7024.3511 - mae: 7024.3511\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6996.6963 - mae: 6996.6963\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6969.0112 - mae: 6969.0112\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6942.1899 - mae: 6942.1899\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6911.7280 - mae: 6911.7280\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6884.0205 - mae: 6884.0205\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6853.4648 - mae: 6853.4648\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6823.0674 - mae: 6823.0674\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6789.6855 - mae: 6789.6855\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6755.7646 - mae: 6755.7646\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6720.2026 - mae: 6720.2026\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6689.7158 - mae: 6689.7158\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6652.4609 - mae: 6652.4609\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6618.1016 - mae: 6618.1016\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6585.8633 - mae: 6585.8633\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6559.4956 - mae: 6559.4956\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6530.0439 - mae: 6530.0439\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6506.8066 - mae: 6506.8066\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6493.5718 - mae: 6493.5718\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6475.9258 - mae: 6475.9258\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6458.8979 - mae: 6458.8979\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6445.1494 - mae: 6445.1494\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6430.9639 - mae: 6430.9639\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6417.7510 - mae: 6417.7510\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6403.2759 - mae: 6403.2759\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6392.4141 - mae: 6392.4141\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6378.7451 - mae: 6378.7451\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6364.9131 - mae: 6364.9131\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6351.5273 - mae: 6351.5273\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6337.6602 - mae: 6337.6602\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6324.8369 - mae: 6324.8369\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6310.1943 - mae: 6310.1943\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6295.6035 - mae: 6295.6035\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6284.8696 - mae: 6284.8696\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6265.6411 - mae: 6265.6411\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6253.0112 - mae: 6253.0112\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6234.9292 - mae: 6234.9292\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6218.0435 - mae: 6218.0435\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6201.1899 - mae: 6201.1899\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6183.9590 - mae: 6183.9590\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6171.2993 - mae: 6171.2993\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6148.8398 - mae: 6148.8398\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6132.5981 - mae: 6132.5981\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6112.3853 - mae: 6112.3853\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6092.7202 - mae: 6092.7202\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6073.7422 - mae: 6073.7422\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6059.4873 - mae: 6059.4873\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6031.3848 - mae: 6031.3848\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6010.3350 - mae: 6010.3350\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5995.2178 - mae: 5995.2178\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5963.0723 - mae: 5963.0723\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5940.0605 - mae: 5940.0605\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5915.1064 - mae: 5915.1064\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5887.9990 - mae: 5887.9990\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5861.6992 - mae: 5861.6992\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5834.3066 - mae: 5834.3066\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5805.8237 - mae: 5805.8237\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5772.3232 - mae: 5772.3232\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5745.1514 - mae: 5745.1514\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5711.3477 - mae: 5711.3477\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5674.5215 - mae: 5674.5215\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5639.4927 - mae: 5639.4927\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5600.6655 - mae: 5600.6655\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5559.4326 - mae: 5559.4326\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5523.6187 - mae: 5523.6187\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5474.1250 - mae: 5474.1250\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5432.2656 - mae: 5432.2656\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5386.0527 - mae: 5386.0527\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5333.1812 - mae: 5333.1812\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5288.8159 - mae: 5288.8159\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5234.6792 - mae: 5234.6792\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5170.9360 - mae: 5170.9360\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5112.9443 - mae: 5112.9443\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5059.8643 - mae: 5059.8643\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6533378690>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the larger model\n",
        "insurance_model_2.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq8e4WS2GWpK",
        "outputId": "f650ec53-83c1-4e9f-ff56-cd213ad96e7c"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 4924.3477 - mae: 4924.3477\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4924.34765625, 4924.34765625]"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "insurance_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jKgqI65GbNe",
        "outputId": "2f1568d4-198c-4783-9afb-6d6c72a52e71"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 7023.3291 - mae: 7023.3291\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7023.3291015625, 7023.3291015625]"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The new model provided an improvement of 30%, the error went down significantly!\n",
        "# We did two changes:\n",
        "# Added an extra layer\n",
        "# Chaned the optimizer (as SGD was not learning)\n",
        "\n",
        "# So Experiment 1 was modified to adding an extra layer and use the Adam optimizer (after trying to solve the issue)"
      ],
      "metadata": {
        "id": "SWd9Gxo7Gfl7"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now training for longer, epochs = 200\n",
        "\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "insurance_model_3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(),\n",
        "                          metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "history = insurance_model_3.fit(X_train, y_train, epochs=200)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaIlFG23G2Qy",
        "outputId": "4ec24e50-e6d9-4b8f-e362-ccbc01bf7373"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 1s 2ms/step - loss: 13273.1602 - mae: 13273.1602\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13104.4297 - mae: 13104.4297\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12749.5420 - mae: 12749.5420\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12055.7500 - mae: 12055.7500\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10905.8154 - mae: 10905.8154\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9457.7217 - mae: 9457.7217\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8147.6543 - mae: 8147.6543\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7528.8413 - mae: 7528.8413\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7429.1528 - mae: 7429.1528\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7409.0811 - mae: 7409.0811\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7390.8042 - mae: 7390.8042\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7368.9170 - mae: 7368.9170\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7348.5190 - mae: 7348.5190\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7326.4893 - mae: 7326.4893\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7307.5811 - mae: 7307.5811\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7285.7734 - mae: 7285.7734\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7265.7104 - mae: 7265.7104\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7242.5488 - mae: 7242.5488\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7220.5068 - mae: 7220.5068\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7197.1978 - mae: 7197.1978\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7179.0195 - mae: 7179.0195\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7151.2104 - mae: 7151.2104\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7126.4639 - mae: 7126.4639\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7101.9199 - mae: 7101.9199\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7084.3379 - mae: 7084.3379\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7052.3291 - mae: 7052.3291\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7024.3511 - mae: 7024.3511\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6996.6963 - mae: 6996.6963\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6969.0112 - mae: 6969.0112\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6942.1899 - mae: 6942.1899\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6911.7280 - mae: 6911.7280\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6884.0205 - mae: 6884.0205\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6853.4648 - mae: 6853.4648\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6823.0674 - mae: 6823.0674\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6789.6855 - mae: 6789.6855\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6755.7646 - mae: 6755.7646\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6720.2026 - mae: 6720.2026\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6689.7158 - mae: 6689.7158\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6652.4609 - mae: 6652.4609\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6618.1016 - mae: 6618.1016\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6585.8633 - mae: 6585.8633\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6559.4956 - mae: 6559.4956\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6530.0439 - mae: 6530.0439\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6506.8066 - mae: 6506.8066\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6493.5718 - mae: 6493.5718\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6475.9258 - mae: 6475.9258\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6458.8979 - mae: 6458.8979\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6445.1494 - mae: 6445.1494\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6430.9639 - mae: 6430.9639\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6417.7510 - mae: 6417.7510\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6403.2759 - mae: 6403.2759\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6392.4141 - mae: 6392.4141\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6378.7451 - mae: 6378.7451\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6364.9131 - mae: 6364.9131\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6351.5273 - mae: 6351.5273\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6337.6602 - mae: 6337.6602\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6324.8369 - mae: 6324.8369\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6310.1943 - mae: 6310.1943\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6295.6035 - mae: 6295.6035\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6284.8696 - mae: 6284.8696\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6265.6411 - mae: 6265.6411\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6253.0112 - mae: 6253.0112\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6234.9292 - mae: 6234.9292\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6218.0435 - mae: 6218.0435\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6201.1899 - mae: 6201.1899\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6183.9590 - mae: 6183.9590\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6171.2993 - mae: 6171.2993\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6148.8398 - mae: 6148.8398\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6132.5981 - mae: 6132.5981\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6112.3853 - mae: 6112.3853\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6092.7202 - mae: 6092.7202\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6073.7422 - mae: 6073.7422\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6059.4873 - mae: 6059.4873\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6031.3848 - mae: 6031.3848\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6010.3350 - mae: 6010.3350\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5995.2178 - mae: 5995.2178\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5963.0723 - mae: 5963.0723\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5940.0605 - mae: 5940.0605\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5915.1064 - mae: 5915.1064\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5887.9990 - mae: 5887.9990\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5861.6992 - mae: 5861.6992\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5834.3066 - mae: 5834.3066\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5805.8237 - mae: 5805.8237\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5772.3232 - mae: 5772.3232\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5745.1514 - mae: 5745.1514\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5711.3477 - mae: 5711.3477\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5674.5215 - mae: 5674.5215\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5639.4927 - mae: 5639.4927\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5600.6655 - mae: 5600.6655\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5559.4326 - mae: 5559.4326\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5523.6187 - mae: 5523.6187\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5474.1250 - mae: 5474.1250\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5432.2656 - mae: 5432.2656\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5386.0527 - mae: 5386.0527\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5333.1812 - mae: 5333.1812\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5288.8159 - mae: 5288.8159\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5234.6792 - mae: 5234.6792\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5170.9360 - mae: 5170.9360\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5112.9443 - mae: 5112.9443\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5059.8643 - mae: 5059.8643\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4987.6191 - mae: 4987.6191\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4915.2905 - mae: 4915.2905\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4847.3604 - mae: 4847.3604\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4768.0151 - mae: 4768.0151\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4683.4727 - mae: 4683.4727\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4600.5054 - mae: 4600.5054\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4513.1436 - mae: 4513.1436\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4422.2983 - mae: 4422.2983\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4339.9600 - mae: 4339.9600\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4254.3916 - mae: 4254.3916\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4173.1797 - mae: 4173.1797\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4102.2944 - mae: 4102.2944\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4031.9590 - mae: 4031.9590\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3986.0220 - mae: 3986.0220\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3943.2346 - mae: 3943.2346\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3918.8977 - mae: 3918.8977\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3895.5610 - mae: 3895.5610\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3869.5679 - mae: 3869.5679\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3850.2136 - mae: 3850.2136\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3834.7349 - mae: 3834.7349\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3827.0952 - mae: 3827.0952\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3821.6382 - mae: 3821.6382\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3813.8315 - mae: 3813.8315\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3805.7307 - mae: 3805.7307\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3794.7085 - mae: 3794.7085\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3804.4946 - mae: 3804.4946\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3796.0596 - mae: 3796.0596\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3791.0422 - mae: 3791.0422\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3800.0696 - mae: 3800.0696\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3788.5005 - mae: 3788.5005\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3780.8442 - mae: 3780.8442\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3774.5413 - mae: 3774.5413\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3771.0156 - mae: 3771.0156\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3769.3762 - mae: 3769.3762\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3766.7612 - mae: 3766.7612\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3765.5510 - mae: 3765.5510\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3774.5034 - mae: 3774.5034\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3785.3909 - mae: 3785.3909\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3761.1299 - mae: 3761.1299\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3764.1753 - mae: 3764.1753\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3763.9250 - mae: 3763.9250\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3762.7959 - mae: 3762.7959\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3754.4397 - mae: 3754.4397\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3750.3347 - mae: 3750.3347\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3750.4006 - mae: 3750.4006\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3755.4736 - mae: 3755.4736\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3750.3223 - mae: 3750.3223\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3758.1089 - mae: 3758.1089\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3743.4858 - mae: 3743.4858\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3738.5342 - mae: 3738.5342\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3740.1384 - mae: 3740.1384\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3742.4954 - mae: 3742.4954\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3744.4395 - mae: 3744.4395\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3737.1826 - mae: 3737.1826\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3737.6541 - mae: 3737.6541\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3737.1663 - mae: 3737.1663\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3733.1101 - mae: 3733.1101\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3729.5813 - mae: 3729.5813\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3725.9053 - mae: 3725.9053\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3733.2822 - mae: 3733.2822\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3728.2559 - mae: 3728.2559\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3724.5825 - mae: 3724.5825\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3723.0806 - mae: 3723.0806\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3726.9475 - mae: 3726.9475\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3716.5430 - mae: 3716.5430\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3721.9155 - mae: 3721.9155\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3721.1814 - mae: 3721.1814\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3715.2458 - mae: 3715.2458\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3713.9756 - mae: 3713.9756\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3707.9922 - mae: 3707.9922\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3707.4158 - mae: 3707.4158\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3710.6833 - mae: 3710.6833\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3703.3618 - mae: 3703.3618\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3710.9385 - mae: 3710.9385\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3713.0417 - mae: 3713.0417\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3705.0571 - mae: 3705.0571\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3698.9333 - mae: 3698.9333\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3697.9983 - mae: 3697.9983\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3704.9150 - mae: 3704.9150\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3710.3679 - mae: 3710.3679\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3696.6482 - mae: 3696.6482\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3692.7329 - mae: 3692.7329\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3691.1655 - mae: 3691.1655\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3699.2437 - mae: 3699.2437\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3693.2480 - mae: 3693.2480\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3696.1389 - mae: 3696.1389\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3687.8640 - mae: 3687.8640\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3693.3562 - mae: 3693.3562\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3682.7324 - mae: 3682.7324\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3683.2891 - mae: 3683.2891\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3697.6536 - mae: 3697.6536\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3684.6665 - mae: 3684.6665\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3675.5154 - mae: 3675.5154\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3676.3923 - mae: 3676.3923\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3672.8452 - mae: 3672.8452\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3682.0283 - mae: 3682.0283\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3665.7961 - mae: 3665.7961\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3671.7419 - mae: 3671.7419\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3680.5464 - mae: 3680.5464\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3665.6401 - mae: 3665.6401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate our third model\n",
        "insurance_model_3.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8non805tHaxh",
        "outputId": "24b45871-a4c5-4123-d30c-9b75efc0aa99"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3491.2961 - mae: 3491.2961\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3491.296142578125, 3491.296142578125]"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "insurance_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NV-hYrPIQtz",
        "outputId": "8f899986-11ac-4962-bc70-2a7c56232e89"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 7023.3291 - mae: 7023.3291\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7023.3291015625, 7023.3291015625]"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "insurance_model_2.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmBVdbNkIVir",
        "outputId": "3199dd80-62c5-4a28-dc85-0bc89188dc98"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 4924.3477 - mae: 4924.3477\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4924.34765625, 4924.34765625]"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# So insurance_model_3 is the best model so far!!\n",
        "# We could try more things but let's see the history variable that we just stored now..."
      ],
      "metadata": {
        "id": "8Em665EQIWLL"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot history (also known as a loss curve or a training curve)\n",
        "\n",
        "pd.DataFrame(history.history).plot()   # history attribute of history has the values!\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epochs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "oP54wwd6IgPo",
        "outputId": "24645551-476d-42a6-f5d8-1d46116834b0"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 130
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxcdb3/8ddnMtm3pum+0RRaShegtaVFEFmUAqK4IugViihuV+RyBUG8P7336nW9csENUdmUVXBBBdlUKEp3upfSULqka5o2aZp9Zj6/P+YEQ2lLmszMSTrv5+Mxj5z5zpk5nzmZzDvfs3yPuTsiIiI9EQm7ABER6b8UIiIi0mMKERER6TGFiIiI9JhCREREeiwadgGZNmjQIB87dmzYZYiI9CtLlizZ7e6DD2zPuhAZO3YsixcvDrsMEZF+xcw2Haxdm7NERKTHFCIiItJjChEREemxrNsnIiLSUx0dHdTU1NDa2hp2KWlTUFDAqFGjyM3N7db8ChERkW6qqamhtLSUsWPHYmZhl5Ny7k5dXR01NTVUVVV16znanCUi0k2tra1UVlYelQECYGZUVlYeUU9LISIicgSO1gDpdKTvTyHSDYl4nIUPf5+lj98ZdikiIn2KQqQbzIyKl+5j0KLvkojHwy5HRLJYSUlJ2CW8jkKkGywSoeGkTzImsZWVzz4SdjkiIn2GQqSbTpozl10MJLLgx2GXIiKCu3PdddcxZcoUpk6dyoMPPgjA9u3bOeOMMzj55JOZMmUK8+bNIx6PM3fu3Nfmvfnmm1NWhw7x7abcvHxeqfoIp776Q7ZUr2T0cVPDLklEQvSff1jNmm37Uvqak0aU8dV3T+7WvL/5zW9YtmwZy5cvZ/fu3cycOZMzzjiD++67jzlz5nDTTTcRj8dpbm5m2bJlbN26lVWrVgFQX1+fsprVEzkCI2Z/CIDtK/8aciUiku2ef/55Lr30UnJychg6dChvf/vbWbRoETNnzuTOO+/ka1/7GitXrqS0tJRx48axYcMGPv/5z/PnP/+ZsrKylNWhnsgRGH3cVBq9EK9ZEnYpIhKy7vYYMu2MM87gueee409/+hNz587l2muv5bLLLmP58uU88cQT3HbbbTz00EPccccdKVmeeiJHIJKTw6aC4xlYvyrsUkQky73tbW/jwQcfJB6PU1tby3PPPccpp5zCpk2bGDp0KJ/85Cf5xCc+wdKlS9m9ezeJRIIPfOADfP3rX2fp0qUpq0M9kSPUWHkix2+9l9aWJgoKi8MuR0Sy1Pve9z5eeOEFTjrpJMyM73znOwwbNoy7776b7373u+Tm5lJSUsI999zD1q1bueKKK0gkEgB885vfTFkd5u4pe7H+YMaMGd6bi1K9+MTdTHvhatZd+FuOn3F2CisTkb5u7dq1nHDCCWGXkXYHe59mtsTdZxw4rzZnHaERk08HYO/6+SFXIiISPoXIERoyoordDCC6PXXbFEVE+iuFyBGySITt+VWUNm8OuxQRkdApRHqgtXAYFbHasMsQEQmdQqQHYsXDGOj1xDrawy5FRCRUCpEeiJSPJGoJ9uzaGnYpIiKhUoj0QP7AUQDU79wUciUiIuFSiPRAyeDRAOyv3RJyJSIi4VKI9EDFsLEAtO9RiIhI5mzcuJGJEycyd+5cJkyYwEc/+lGefvppTjvtNMaPH8/ChQtZuHAhp556KtOmTeOtb30r69atAyAej3Pdddcxc+ZMTjzxRH7605+mpCYNe9IDFYOG0+45+L7tYZciImF5/AbYsTK1rzlsKpz/rcPOUl1dza9//WvuuOMOZs6cyX333cfzzz/Po48+yv/8z/9wzz33MG/ePKLRKE8//TRf/vKXeeSRR/jFL35BeXk5ixYtoq2tjdNOO41zzz2XqqqqXpWsEOmBSE4OuyOV5DZtC7sUEckyVVVVTJ2avJ7R5MmTOeecczAzpk6dysaNG2loaODyyy9n/fr1mBkdHR0APPnkk6xYsYKHH34YgIaGBtavX68QCUtDdBCFrbvCLkNEwvImPYZ0yc/Pf206Eom8dj8SiRCLxfiP//gPzjrrLH7729+yceNGzjzzTCB5JcQf/OAHzJkzJ6X1aJ9IDzXnD6G8Qyccikjf0tDQwMiRIwG46667XmufM2cOP/nJT17rmbz88ss0NTX1enkKkR7qKB5OZaIOD4ZWFhHpC66//npuvPFGpk2bRiwWe639E5/4BJMmTWL69OlMmTKFT33qU697vKfSNhS8md0BXAjscvcpQdt3gXcD7cArwBXuXh88diNwJRAHrnb3J4L284BbgBzg5+7+raC9CngAqASWAB9z9zc9hby3Q8F3mn/vfzJ7/fdpuLqa8oGDe/16ItL3aSj4zA4Ffxdw3gFtTwFT3P1E4GXgxqC4ScAlwOTgOT82sxwzywF+BJwPTAIuDeYF+DZws7sfB+wlGUAZk1uRPOFwz/YNmVysiEifkrYQcffngD0HtD3p7p39p/nAqGD6IuABd29z91eBauCU4Fbt7huCXsYDwEVmZsDZwMPB8+8G3puu93IwhQOT2xz31+kILRHJXmHuE/k48HgwPRLoeuZeTdB2qPZKoL5LIHW2H5SZXWVmi81scW1tanaGF5ZVAtC+f8+bzCkiR5Oj/WqwR/r+QgkRM7sJiAH3ZmJ57n67u89w9xmDB6dm/0Vx+SAAYk31KXk9Een7CgoKqKurO2qDxN2pq6ujoKCg28/J+HkiZjaX5A73c/yfv4mtwOgus40K2jhEex0wwMyiQW+k6/wZUVI+EIBEi0JEJFuMGjWKmpoaUrVFoy8qKChg1KhRbz5jIKMhEhxpdT3wdndv7vLQo8B9ZvZ9YAQwHlgIGDA+OBJrK8md7x9xdzezvwIfJLmf5HLg95l7J1BYVEq754BCRCRr5Obm9voM76NN2jZnmdn9wAvA8WZWY2ZXAj8ESoGnzGyZmd0G4O6rgYeANcCfgc+5ezzoZfwr8ASwFngomBfgS8C1ZlZNch/JL9L1Xg7GIhEarYRIe0MmFysi0qekrSfi7pcepPmQX/Tu/g3gGwdpfwx47CDtG0gevRWaZism2qYQEZHspTPWe6E5p5TcWGPYZYiIhEYh0gtt0VIKFCIiksUUIr3QkVtGYXx/2GWIiIRGIdILsbwySlwhIiLZSyHSC4n8ckq8SSP5ikjWUoj0ghUOINfiNDftC7sUEZFQKER6IVI4AIDG+t0hVyIiEg6FSC9EiysAaNlXF3IlIiLhUIj0Qm5xcvysln0ayVdEspNCpBcKypIh0r5/b8iViIiEQyHSC0VBiHQ0qSciItlJIdILJcE1ReLNGslXRLKTQqQXSsqTVzd0DQcvIllKIdILOdEojV6IaSRfEclSCpFe2m8l5ChERCRLKUR6qTmnhGiHRvIVkeykEOml1pxS8js07ImIZCeFSC+1R0so0HDwIpKlFCK9FI8WU+AtYZchIhIKhUgvxXOLKVSIiEiWUoj0UiKvhCKFiIhkKYVIb+WVkG8ddLS3hV2JiEjGKUR6yfJLAWhu1FnrIpJ9FCK9lFMQhMh+hYiIZB+FSC/lFJYB0KoQEZEspBDppWgQIm26zrqIZCGFSC/lFSVDpL1ZISIi2Uch0kv5xckQibUoREQk+yhEeim/eAAAsVYNwigi2Uch0ktFJeUAJBQiIpKFFCK9VFSa7Il4m0JERLKPQqSX8vILaPcotDWFXYqISMalLUTM7A4z22Vmq7q0DTSzp8xsffCzImg3M7vVzKrNbIWZTe/ynMuD+deb2eVd2t9iZiuD59xqZpau9/JmmqyISLt2rItI9klnT+Qu4LwD2m4AnnH38cAzwX2A84Hxwe0q4CeQDB3gq8As4BTgq53BE8zzyS7PO3BZGdNiheR0qCciItknbSHi7s8Bew5ovgi4O5i+G3hvl/Z7PGk+MMDMhgNzgKfcfY+77wWeAs4LHitz9/nu7sA9XV4r41qtkJyYQkREsk+m94kMdfftwfQOYGgwPRLY0mW+mqDtcO01B2kPRVtOEbnx5rAWLyISmtB2rAc9CM/EsszsKjNbbGaLa2trU/76HTnF5ClERCQLZTpEdgabogh+7gratwKju8w3Kmg7XPuog7QflLvf7u4z3H3G4MGDe/0mDhSLFpGfUIiISPbJdIg8CnQeYXU58Psu7ZcFR2nNBhqCzV5PAOeaWUWwQ/1c4IngsX1mNjs4KuuyLq+VcbFoMYUKERHJQtF0vbCZ3Q+cCQwysxqSR1l9C3jIzK4ENgEXB7M/BlwAVAPNwBUA7r7HzP4bWBTM91/u3rmz/rMkjwArBB4PbqFI5JXoOusikpXSFiLufukhHjrnIPM68LlDvM4dwB0HaV8MTOlNjSmTV0oxrXgigUV0/qaIZA9946VCfgkRc5p1TRERyTIKkRTovM56S2NDyJWIiGSWQiQFOq+z3tKkS+SKSHZRiKRA5yVyW7U5S0SyjEIkBaJFyZ5Iu0JERLKMQiQFOq9u2NGsfSIikl0UIilQUBJcIlfXWReRLKMQSYHCIETiLeqJiEh2UYikQEn5QAASreqJiEh2UYikQH5+Ie2eA20KERHJLgqRFLBIhCYrJqIQEZEsoxBJkWYrJKdjf9hliIhklEIkRVoiJUQVIiKSZRQiKdKWU0ReXNdZF5HsohBJkfZoKflx9UREJLsoRFIkrqsbikgWUoikSDyvlCLX5iwRyS4KkRRJ5JVS7C14IhF2KSIiGdOtEDGzYjOLBNMTzOw9Zpab3tL6mYJyci1Oa4t6IyKSPbrbE3kOKDCzkcCTwMeAu9JVVH8UCS5M1dSwJ+RKREQyp7shYu7eDLwf+LG7fwiYnL6y+p+cwnIAmvfvDbkSEZHM6XaImNmpwEeBPwVtOekpqX/KLU6GSOt+XSJXRLJHd0PkGuBG4LfuvtrMxgF/TV9Z/U9uUXI4+Lb9Gg5eRLJHtDszufuzwLMAwQ723e5+dToL628KSioA6GjW5iwRyR7dPTrrPjMrM7NiYBWwxsyuS29p/Yuubigi2ai7m7Mmufs+4L3A40AVySO0JFBcFlyYSlc3FJEs0t0QyQ3OC3kv8Ki7dwCevrL6n+LS5I5119UNRSSLdDdEfgpsBIqB58zsGEDfll1Ec/No9nysrTHsUkREMqa7O9ZvBW7t0rTJzM5KT0n9V5MVEWlXtopI9ujujvVyM/u+mS0Obv9LslciXTRHinVhKhHJKt3dnHUH0AhcHNz2AXemq6j+qi1SRDSmEBGR7NGtzVnAse7+gS73/9PMlqWjoP6sLaeE/JgGYBSR7NHdnkiLmZ3eecfMTgNa0lNS/9WRW0JBQj0REcke3Q2RTwM/MrONZrYR+CHwqZ4u1Mz+zcxWm9kqM7vfzArMrMrMFphZtZk9aGZ5wbz5wf3q4PGxXV7nxqB9nZnN6Wk9qdJeOJRB8d26poiIZI1uhYi7L3f3k4ATgRPdfRpwdk8WGAwnfzUww92nkBzI8RLg28DN7n4csBe4MnjKlcDeoP3mYD7MbFLwvMnAecCPzSzcQSHLR1Fsreyrrwu1DBGRTDmiKxu6+77gzHWAa3ux3ChQaGZRoAjYTjKUHg4ev5vkiY0AFwX3CR4/x8wsaH/A3dvc/VWgGjilFzX1Wl7lMQDsrlkfZhkiIhnTm8vjWk+e5O5bge8Bm0mGRwOwBKh391gwWw0wMpgeCWwJnhsL5q/s2n6Q57y+ULOrOg9Prq2t7UnZ3VIydBwA+3ZsSNsyRET6kt6ESI+GPTGzCpK9iCpgBMnzTc7rRR1vyt1vd/cZ7j5j8ODBaVtO5chjAWir25y2ZYiI9CWHPcTXzBo5eFgYUNjDZb4DeNXda4Nl/AY4DRhgZtGgtzEK2BrMvxUYDdQEm7/Kgbou7Z26PicUAwePoNVzoV4hIiLZ4bA9EXcvdfeyg9xK3b2755gcaDMw28yKgn0b5wBrSF7k6oPBPJcDvw+mHw3uEzz+F3f3oP2S4OitKmA8sLCHNaWERSLURgaT1xRqlomIZExPg6DH3H2BmT0MLAViwIvA7SQvu/uAmX09aPtF8JRfAL80s2pgD8kjsgiusPgQyQCKAZ9z93hG38xB1OcNo6R1R9hliIhkRMZDBMDdvwp89YDmDRzk6Cp3bwU+dIjX+QbwjZQX2AstRSMYvvf5sMsQEcmI3uxYl4OIl41iEPW0tmj4ExE5+ilEUixaMQaA2q06zFdEjn4KkRQrGlIFQP02hYiIHP0UIik2dOxkEm60LH0g7FJERNJOIZJig0Ycw4JRczml/jEWPvx9EvHQDxgTEUkbS55ykT1mzJjhixcvTusyYh3tvPyds5jUsYq9lLKhdCbxcWcx9pR3M2RkVVqXLSKSDma2xN1nvKFdIZIezfsbWPOX+/FX/kJVwwIGUQ/AxsgYdgx+K0UnnMv4medSWFya9lpERHpLIRLIVIh05YkEr65ZxK5lj1G85VkmtK4i3zpo81xeLphC0+i3M+TkC6iaNBOLaAujiPQ9CpFAGCFyoJamRtYvepLmtU8yrPYfjE0kx9qqpYJXB55O/pQLOX72hRQUlYRap4hIJ4VIoC+EyIF21rzCpkV/IvrKUxzfuJBia6XZ81lXMpOOqnMYfvI7GX3c1LDLFJEsphAJ9MUQ6aqttZl1LzxGy6o/UFX3HEPYA8CGyFh2jn0PVWdexrAx40OuUkSyjUIk0NdDpCtPJNhSvYJtSx5jwCuPMjG2FoCXoiewd/Q5VEw6i/HTziQnGsoQaCKSRRQigf4UIgfaumEtm5+7myFbnuDYePKM+G02hM3HfIjjzvs0g4aNCblCETlaKUQC/TlEuqrbWcOrix6jYOW9TGlbRofnsKrkVGz6x5hyxvuJ5uaFXaKIHEUUIoGjJUS62rJ+OVuf+Snjd/yRShrYzQDWD38PI8+6kjETTg67PBE5CihEAkdjiHTqaG9j1d9+DcvuZWrTfKKWYG3uJPafcAknvOMySsoqwi5RRPophUjgaA6Rrnbv2Ez1Uz9nxKsPMyaxlWbPZ1XFOZSf/kmOn3F22OWJSD+jEAlkS4h08kSCdYufYd8LdzJ5zzMUWysvRyew78SPM/Xcy8kvKAq7RBHpBxQigWwLka7279vL6sd/yvB19zAmsZVaKqge9zEmvfsLlFcMCrs8EenDFCKBbA6RTol4nFXzfoe98EOmti2lyQtYOex9jL3wiwwbfVzY5YlIH6QQCShEXq96+d+pf+b7nNzwFxxjefnZVLzzixw7dXbYpYlIH6IQCShEDm7H5vVs/NP3mLrjdxRbKyvzp8NpVzPl9Is0srCIKEQ6KUQOr2FPLWv+8H+Mf/VXDKKejZExbD/mPYw98zKGH3N82OWJSEgUIgGFSPe0tTaz4rGfUbr2ASZ2rAFgbe5k9o1/HyOnn8/IcZPUQxHJIgqRgELkyG179SU2PXsXIzb/kWMSWwBooJjN+cezf9CJFBwzk5GTT9Olf0WOYgqRgEKk5zyRYONLS6hdMw+2LaWyYTXHxDYStQQAdZSzLX8cTQMmkjN8ChVV0xg14WQKCotDrlxEekshElCIpFZr8342rp5PffUCIjtXUbF/PaM7NlJgHQDEPEJNzkjqisfTPugEikafyNDxMxg6cpw2h4n0IwqRgEIk/eKxGFs3rKK2+kXat62gYM9LDGtez3BqX5tnH8XU5I2jsWwCNmwK5WNPZvTEt1BUUh5i5SJyKAqRgEIkPPvq69i2bgkNm5bBztWU73uZ0e0bKLZWABJubIsMY2fJRGJjTmfwCW9jzPHTNKy9SB+gEAkoRPqWRDzOjs3r2bl+Ma1bV5K/ew2jmla9dlngZs9nU96xNFROo+DY0xk77WwGDBoWctUi2UchElCI9H2eSFCzYTU71/ydWM0SBuxZybiO9eRZDIBNkdHsGDCNyDGnMvLEsxl+zATtXxFJs0OFiC7OLX2ORSKMPm4qo4+b+lpba0sTa1c8T/1Lz1K0YxEn7Hmasj2Pwouwi4FsKT2J2MhZDJp8FlWTZhLJyQnxHYhkj1B6ImY2APg5MAVw4OPAOuBBYCywEbjY3feamQG3ABcAzcBcd18avM7lwFeCl/26u9/9ZstWT+ToEI/F2PTSEmpX/41ozXxGNy57bRNYPSVsKJ5Ox5jTqRg/m2MmzdSQ9yK91Kc2Z5nZ3cA8d/+5meUBRcCXgT3u/i0zuwGocPcvmdkFwOdJhsgs4BZ3n2VmA4HFwAySQbQEeIu77z3cshUiRydPJNixZT01Lz4NG+cxun4Rw9gNwD6KWFv5TgqnXsSEU+ZQUFQScrUi/U+fCREzKweWAeO8y8LNbB1wprtvN7PhwN/c/Xgz+2kwfX/X+Tpv7v6poP118x2KQiQ7eCLB9k0vs+OlF0is/ROTG56l0Nrp8Bw2Rceye+yFnPCuz1M+cHDYpYr0C31pn0gVUAvcaWYnkexBfAEY6u7bg3l2AEOD6ZHAli7PrwnaDtX+BmZ2FXAVwJgxY1LzLqRPs0iEEVUTGVE1Ec6/gpamRpYv/DPN1c9TsWshs1+5hfZbfsjywum0jb+Q8Wd8mIrBw8MuW6TfCSNEosB04PPuvsDMbgFu6DqDu7uZpayL5O63A7dDsieSqteV/qOwuJSTzvoQnPUhAF5ZOZ/av9/DmJ1PM2LlV+lY8V8sKz6FxNQPM/msD2sfikg3hREiNUCNuy8I7j9MMkR2mtnwLpuzdgWPbwVGd3n+qKBtK8lNWl3b/5bGuuUocuzU2Rw7dTaeSFC98gVq59/HsdsfY8iCa9i34CaWVb6T8tkf4/i3nK3Dh0UOI6wd6/OAT7j7OjP7GtA5Ql9dlx3rA939ejN7F/Cv/HPH+q3ufkqwY30JyV4NwFKSO9b3HG7Z2icihxKPxVjzjz/QtvhXTG54jkJrZ4uNYNvEy5lywacpLh0QdokioekzO9aDYk4meYhvHrABuAKIAA8BY4BNJA/x3RMc4vtD4DySh/he4e6Lg9f5OMmjugC+4e53vtmyFSLSHfv37WXNM7+ifPUvOT62jmbPZ/WAM6l8578zbsqssMsTybg+FSJhUojIkfBEgnVL/sK+F+5ict1TFFsrywtnkX/mF5k469ywyxPJGIVIQCEiPdWwp5Y1v/8eEzfdSwWNrMmdQvz0f2fK296r/SZy1DtUiOiTL9JN5QMHc+oV3yb/i6uZP+E6Kju2M/WvV7D2W2ewdsETYZcnEgqFiMgRKiopZ/ZHvsKAG1ax4IQbGdK+hRMev5gV33oH65fNC7s8kYxSiIj0UH5BEbM+fAPF161i/rFfYEzrWsb/7kIW/OAyGhsOe5CgyFFDISLSS4XFpcz+2H8RuWYF84deyszdj9Jy81tY8tgv8EQi7PJE0kohIpIiZQMqmf2Z23j53Y/QmDOAtyy8ljXfOpONa3Ughxy9FCIiKTZxxjmMvXERCybdxKj2akY8MIf5v/oaiXg87NJEUk4hIpIGOdEosy6+nsTnlrC6eBazq29m/TdPpXr582GXJpJSChGRNKoYPJyTv/hHFk37JpWxnYz9zbuZf9eXicdiYZcmkhIKEZE0s0iEmRd9ltwvLGF52ZnM3vgjVn3vPBr27g67NJFeU4iIZEh5xSCm/9sjLJj0FSa1LKXhB2ewZf3ysMsS6RWFiEgGWSTCrIuvY/1591KaaKT83vNY9swDYZcl0mMKEZEQTDr1fFrmPk1tzjBOnvcpFvzoSmId7WGXJXLEFCIiIRkx9nhGfvF55g+5mFm1D7Pilg/S0d4WdlkiR0QhIhKigsJiZn/2Z8w/7t+Yvv9ZVt3yftrbWsMuS6TbFCIifcDsf/ka8ydcx7Sm51lzy3tpa20OuySRblGIiPQRsz/yFRac8GVObn6Bl265iNaWprBLEnlTChGRPmTWh7/Egsn/j5NaFvLyLe+mtXl/2CWJHJZCRKSPmfWhf2fhSf/NlJalVN/yLgWJ9GkKEZE+6JT3Xc2S6f/DpNblrPnRJRomRfoshYhIHzXzos+ycMK1TG+ax6KffS7sckQOSiEi0ofNuvQrzB/8IWbvfID593097HJE3kAhItKHWSTCzE/dxotFp3HKuu+x9Ilfhl2SyOsoRET6uJxolImfe5D1uROY9I9/46XFz4RdkshrFCIi/UBhcSmDr/otuyOVDP3jXGqqV4VdkgigEBHpNwYOGYl/5CHA4d4Psrd2e9gliShERPqT0eNPYucFdzI4sZudP32fziGR0ClERPqZiae8k9Wnfo8JHS+x5keXkojHwy5JsphCRKQfmn7e3OAckudYeLvOIZHwKERE+ql/nkNyP/Pv/0bY5UiWUoiI9FOvO4fkpe/qHBIJhUJEpB/reg7JlH9cw4tP/irskiTLhBYiZpZjZi+a2R+D+1VmtsDMqs3sQTPLC9rzg/vVweNju7zGjUH7OjObE847EQlXYXEpwz7zBzbmjmPq3z/P4j/eHnZJkkXC7Il8AVjb5f63gZvd/ThgL3Bl0H4lsDdovzmYDzObBFwCTAbOA35sZjkZql2kTymvHMqIq59kXf4Upi+6ngUPfQdPJMIuS7JAKCFiZqOAdwE/D+4bcDbwcDDL3cB7g+mLgvsEj58TzH8R8IC7t7n7q0A1cEpm3oFI31NSVsGx1zzOyqKZzFrzDVZ9+2w2vbQ07LLkKBdWT+T/gOuBzn+VKoF6d++8aEINMDKYHglsAQgebwjmf639IM95HTO7yswWm9ni2traVL4PkT6loKiEydf+iQUTb+CYtnWMuP8dzP/xJ1m/bJ56JpIWGQ8RM7sQ2OXuSzK1THe/3d1nuPuMwYMHZ2qxIqGI5uYx65Ib6fjMIl6smMPMnb9m/O8uZNd/HceCH36cVfN+T0d7W9hlylEiGsIyTwPeY2YXAAVAGXALMMDMokFvYxSwNZh/KzAaqDGzKFAO1HVp79T1OSJZr3LoKCqvuZ+9tdup/vsjRF9+jBNr/0DhM4+w75lilpfOJj5yJsWjJlM2ZAyDRlRRVFIedtnSz5i7h7dwszOBL7r7hWb2a+ARd3/AzG4DVrj7j83sc8BUd/+0mV0CvN/dLzazycB9JPeDjACeAca7+2HHgJgxY4YvXrw4re9LpK9qaWrkpb//ntjqP1DVMJ9B1L/u8X0UsScyiDkOw3kAAApRSURBVH15Q2gtGEK8aBDR5loisRZihYNIFA+GSC6Rxm0kCgaQM3AsxUOPpaRyBMXlAykdMIj8gqI3LLepsZ5dm9fRVL+LY08+k8Li0ky9ZUkRM1vi7jPe0N6HQmQc8AAwEHgR+Bd3bzOzAuCXwDRgD3CJu28Inn8T8HEgBlzj7o+/2TIVIiJJnkiwc+sGdm9eS2tdDR17a4g0biOveScl7bsYENtNhTewxwbQZgWUez1lNAPQ6IUU00rE3vj9EXejnVw6LEqMKIZTQeNrj7d4HtuiI8nxGDnB/3xxy6Elp4zWvAra8wdC5PUbSSzWSn7bbtoKhpAYfALRkkrA8FgbiVg7HmsDTxAtHUK0sOyfz4vmkldURl5ROQXF5eQXFdO4Zycdrc3kF5aQX1xGQVEpBcWltLW2YGaUDahMw9ru//pkiIRBISLSfZ5IYJF/7jptbWki1tFOSVkF7W2t7NpSzd5t62nbV0u8aS+Jlr0Qa8NibZDowOLtACTKRpE3eBzRgmJa1zxBfvN2EhbFI1HAsEQH+R0NFMf2UprYR4TXHwQQI8q+nAoq47sYQHpHLm6gGMMp9DZayaPVCmizfOIWJUEOCQtu5BCP5NKaNxBwCtvqiCbaiEfyaM6rpKNwMIn8MrAIkdZ6oq17yOtooLVwGLGKcVheCZG8QnAnvm8HFolihWV4RyuWX0pu2RBizfXk5JdQOqyKSE6Uxp0baduxjuiAkZSNOoEhY47HIjl0tDbT3t5KR1sLBcWlDBlRhUUitLU2s7d2GwMGDaegsLhX60UhElCIiPRfnkhQX7eT/fW7AMjJLSAvr4Dc/AIA6ndvp6P1nyETa2+lo3kfHS37iLU04u3NREsqySkoId66n0RbE/G2/Xh7ExYtAI9jezfikVw8twiLtRDpaCYSa8E8/tot4jHM40QT7ZR21OFmNEYHEsspJCfRTklHHQMSeyn1JgxotCIaIgNoiZRQGdv5hs2IqVZHORESr/UAOzyHzdFjGPTZP1NeObRHr3moEAljx7qISI9YJELF4OFUDB5+0Md7+gWZbuXBrVNLUyNtLU20tuwHdwYOHU0iHqOpsZ68giKaG/fSWLeDwtKBtO7fS+POjbgnKBw4nOHHnkT9zs3s2byGttoNYBEsmo/l5hPJLSC+vw7bsQLPySNRMoxIyWASezdTUF/NuIrUH52qnoiIiLypQ/VENACjiIj0mEJERER6TCEiIiI9phAREZEeU4iIiEiPKURERKTHFCIiItJjChEREemxrDvZ0MxqgU09fPogYHcKy0kV1XXk+mptquvI9NW6oO/W1tO6jnH3N5zynnUh0htmtvhgZ2yGTXUdub5am+o6Mn21Lui7taW6Lm3OEhGRHlOIiIhIjylEjsztYRdwCKrryPXV2lTXkemrdUHfrS2ldWmfiIiI9Jh6IiIi0mMKERER6TGFSDeY2Xlmts7Mqs3shpBrGW1mfzWzNWa22sy+ELR/zcy2mtmy4HZBCLVtNLOVwfIXB20DzewpM1sf/KzIcE3Hd1kny8xsn5ldE9b6MrM7zGyXma3q0nbQdWRJtwafuxVmNj3DdX3XzF4Klv1bMxsQtI81s5Yu6+62DNd1yN+dmd0YrK91ZjYnw3U92KWmjWa2LGjP5Po61PdD+j5j7q7bYW5ADvAKMA7IA5YDk0KsZzgwPZguBV4GJgFfA74Y8rraCAw6oO07wA3B9A3At0P+Xe4AjglrfQFnANOBVW+2joALgMcBA2YDCzJc17lANJj+dpe6xnadL4T1ddDfXfB3sBzIB6qCv9ucTNV1wOP/C/y/ENbXob4f0vYZU0/kzZ0CVLv7BndvBx4ALgqrGHff7u5Lg+lGYC0wMqx6uuEi4O5g+m7gvSHWcg7wirv3dMSCXnP354A9BzQfah1dBNzjSfOBAWZ28IuLp6Eud3/S3WPB3fnAqHQs+0jrOoyLgAfcvc3dXwWqSf79ZrQuMzPgYuD+dCz7cA7z/ZC2z5hC5M2NBLZ0uV9DH/nSNrOxwDRgQdD0r0GX9I5MbzYKOPCkmS0xs6uCtqHuvj2Y3gEMDaGuTpfw+j/ssNdXp0Oto7702fs4yf9YO1WZ2Ytm9qyZvS2Eeg72u+sr6+ttwE53X9+lLePr64Dvh7R9xhQi/ZSZlQCPANe4+z7gJ8CxwMnAdpLd6Uw73d2nA+cDnzOzM7o+6Mn+cyjHlJtZHvAe4NdBU19YX28Q5jo6FDO7CYgB9wZN24Ex7j4NuBa4z8zKMlhSn/zddXEpr/9nJePr6yDfD69J9WdMIfLmtgKju9wfFbSFxsxySX5A7nX33wC4+053j7t7AvgZaerGH467bw1+7gJ+G9Sws7N7HPzclem6AucDS919Z1Bj6Ouri0Oto9A/e2Y2F7gQ+Gjw5UOwuagumF5Cct/DhEzVdJjfXV9YX1Hg/cCDnW2ZXl8H+34gjZ8xhcibWwSMN7Oq4L/ZS4BHwyom2N76C2Ctu3+/S3vX7ZjvA1Yd+Nw011VsZqWd0yR3yq4iua4uD2a7HPh9Juvq4nX/HYa9vg5wqHX0KHBZcATNbKChyyaJtDOz84Drgfe4e3OX9sFmlhNMjwPGAxsyWNehfnePApeYWb6ZVQV1LcxUXYF3AC+5e01nQybX16G+H0jnZywTRwz09xvJIxheJvkfxE0h13I6ya7oCmBZcLsA+CWwMmh/FBie4brGkTwyZjmwunM9AZXAM8B64GlgYAjrrBioA8q7tIWyvkgG2Xagg+T25ysPtY5IHjHzo+BztxKYkeG6qkluL+/8nN0WzPuB4He8DFgKvDvDdR3ydwfcFKyvdcD5mawraL8L+PQB82ZyfR3q+yFtnzENeyIiIj2mzVkiItJjChEREekxhYiIiPSYQkRERHpMISIiIj2mEBFJATOL2+tHC07ZaM/BKLBhnscickjRsAsQOUq0uPvJYRchkmnqiYikUXBdie9Y8jorC83suKB9rJn9JRhE8BkzGxO0D7XktTuWB7e3Bi+VY2Y/C64R8aSZFQbzXx1cO2KFmT0Q0tuULKYQEUmNwgM2Z324y2MN7j4V+CHwf0HbD4C73f1EkgMb3hq03wo86+4nkbxexeqgfTzwI3efDNSTPAsakteGmBa8zqfT9eZEDkVnrIukgJntd/eSg7RvBM529w3BwHg73L3SzHaTHK6jI2jf7u6DzKwWGOXubV1eYyzwlLuPD+5/Cch196+b2Z+B/cDvgN+5+/40v1WR11FPRCT9/BDTR6Kty3Scf+7PfBfJsY+mA4uCUWRFMkYhIpJ+H+7y84Vg+h8kR4QG+CgwL5h+BvgMgJnlmFn5oV7UzCLAaHf/K/AloBx4Q29IJJ30X4tIahSa2bIu9//s7p2H+VaY2QqSvYlLg7bPA3ea2XVALXBF0P4F4HYzu5Jkj+MzJEeLPZgc4FdB0Bhwq7vXp+wdiXSD9omIpFGwT2SGu+8OuxaRdNDmLBER6TH1REREpMfUExERkR5TiIiISI8pREREpMcUIiIi0mMKERER6bH/D3XbU8zeJQnRAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TADAAAAA!! That's a LOSS CURVE / TRAINING CURVE, and beautifully decreasing!!\n",
        "# The loss decreases as the network starts to learn (the loss function in this case is MAE)\n",
        "# This learning is what this curve is reflecting"
      ],
      "metadata": {
        "id": "OmEA1n68IwOV"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So when we are training neural networks generally we want our loss curve to go down because that means that the predictions our model is making are becoming less and less wrong. "
      ],
      "metadata": {
        "id": "F13OC59w18Y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From the prvious curve it looks that the loss would keep decreasing, maybe not as much as initially though if you train for longer."
      ],
      "metadata": {
        "id": "qCRukPSO2FZR"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Base on that, **Question:** How log should you train for?\n",
        "\n",
        "It depends. Really...it depends on the problem you are working on. However, many people have asked this question before...so, TensorFlow has a solution! It is called the [**EarlyStopping callback**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)\n",
        "\n",
        "The **EarlyStopping** callback is a TF component you can add to your model to stop training once it stops improving a certain metric. So let's say you put the training for X amount of epochs; if the loss stops decreasing for a certain amount of epochs in a row, that means the model stopped improving, then stop training. "
      ],
      "metadata": {
        "id": "nR95chEW2Zmd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing data (normalization and standardization)"
      ],
      "metadata": {
        "id": "LcxEHOQB21C6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting the data ready is probably the most important step in all the modeling pipeline. It consists of:\n",
        "\n",
        "1. Turn all data into numbers (neural networks can't handle strings, like most ML models)\n",
        "2. Make sure all of your tensors are the right shape (othewise we would have issues)\n",
        "3. **Scale features** (normalize or standardize, neural networks tend to prefe normalization).\n",
        "\n",
        "We are going to deal with the third step now!"
      ],
      "metadata": {
        "id": "c6jGeT5c3uKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at the data\n",
        "\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "-EIngYYX6Mul",
        "outputId": "6e6dd28a-830c-440f-ed26-b0c44366cd9d"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
              "0      19  27.900         0           1         0          0           1   \n",
              "1      18  33.770         1           0         1          1           0   \n",
              "2      28  33.000         3           0         1          1           0   \n",
              "3      33  22.705         0           0         1          1           0   \n",
              "4      32  28.880         0           0         1          1           0   \n",
              "...   ...     ...       ...         ...       ...        ...         ...   \n",
              "1333   50  30.970         3           0         1          1           0   \n",
              "1334   18  31.920         0           1         0          1           0   \n",
              "1335   18  36.850         0           1         0          1           0   \n",
              "1336   21  25.800         0           1         0          1           0   \n",
              "1337   61  29.070         0           1         0          0           1   \n",
              "\n",
              "      region_northeast  region_northwest  region_southeast  region_southwest  \n",
              "0                    0                 0                 0                 1  \n",
              "1                    0                 0                 1                 0  \n",
              "2                    0                 0                 1                 0  \n",
              "3                    0                 1                 0                 0  \n",
              "4                    0                 1                 0                 0  \n",
              "...                ...               ...               ...               ...  \n",
              "1333                 0                 1                 0                 0  \n",
              "1334                 1                 0                 0                 0  \n",
              "1335                 0                 0                 1                 0  \n",
              "1336                 0                 0                 0                 1  \n",
              "1337                 0                 1                 0                 0  \n",
              "\n",
              "[1338 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-efbaa496-68b9-4758-acb6-fff8870e5135\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-efbaa496-68b9-4758-acb6-fff8870e5135')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-efbaa496-68b9-4758-acb6-fff8870e5135 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-efbaa496-68b9-4758-acb6-fff8870e5135');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We see for instance how age is in a different scale to BMI, as shown by the plots\n",
        "X['age'].plot(kind=\"hist\")   # distribution of age column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "pMVBn-886V3e",
        "outputId": "0f95ebc3-ae8f-458b-b74f-34c205609607"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f653219ec50>"
            ]
          },
          "metadata": {},
          "execution_count": 134
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[\"bmi\"].plot(kind=\"hist\")   # distribution of bmi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "gaQqwFuY6eSE",
        "outputId": "17cf5319-a525-44be-e1a7-11c8dbd7d583"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f65320baf10>"
            ]
          },
          "metadata": {},
          "execution_count": 135
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# So what if we want to have both of them in a similar scale?\n",
        "# The same is applicable to children that ranges in a much more narrow range!\n",
        "X[\"children\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfMhINzh6pRH",
        "outputId": "2e257fb4-9126-4b37-f1fc-293aef1079cf"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    574\n",
              "1    324\n",
              "2    240\n",
              "3    157\n",
              "4     25\n",
              "5     18\n",
              "Name: children, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# So if we want to get all of them between 0 and 1, in the same scale?\n",
        "# That is what NORMALIZATION does."
      ],
      "metadata": {
        "id": "Mgeu1R8G66fF"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature scaling\n",
        "\n",
        "* **Scale** (also referred to as **normalization**) -> converts all values to between 0 and 1 whilst preserving the original distribution.\n",
        "    * Scikit-learn function: `MinMaxScaler`\n",
        "    * Use: as default scaler with neural networks.\n",
        "\n",
        "* **Standardization** -> removes the mean and divides each value by the standad deviation. \n",
        "    * Scikit-lean function: `StandardScaler`\n",
        "    * Use: transform a feature to have close to *normal distribution* also known as *Gaussian* (caution: this reduces the effect of outliers)\n",
        "\n",
        "In terms of scaling values, neural networks tend to prefer normalization. \n",
        "\n",
        "If you are not sure on which to use, you could try both and see which performs better.\n",
        "\n",
        "Read this amazing article about it: https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02"
      ],
      "metadata": {
        "id": "0vJaVtgh7Kcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We are going to start fresh so we can run the notebook from this point...\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Read the insurance dataframe, so we reinstantiate it here and see what the process of normalization does\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "v2YAmHfx7rIB",
        "outputId": "f008574f-dd5c-4ee2-d4f4-3ec061a1a2ad"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be545f73-b705-42df-bab0-6462e0b80e06\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be545f73-b705-42df-bab0-6462e0b80e06')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-be545f73-b705-42df-bab0-6462e0b80e06 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-be545f73-b705-42df-bab0-6462e0b80e06');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To prepare our data, we can borrow a few classes from Scikit-Learn."
      ],
      "metadata": {
        "id": "fkffojUk9h4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create a column transformer, because our features are in the columns!\n",
        "ct = make_column_transformer(   # very interesting to transforrm some columns in a specific way!!\n",
        "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]),  # turn all these values in this columns between 0 and 1\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])  # ignore the values it does not how to handle\n",
        "    )\n",
        "\n",
        "\n",
        "# Create X & y\n",
        "X = insurance.drop(\"charges\", axis=1)\n",
        "y = insurance[\"charges\"]\n",
        "\n",
        "\n",
        "# Build train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)   # exact split as before\n",
        "\n",
        "# Fit the column transformer to our training data (only)\n",
        "# ALWAYS FIT AND TRANSFORM THE TRANSFORMER ON THE TRAINING DATA and TRANSFORM (NOT FIT) THE TESTING DATA\n",
        "# AS TEST DATA IS UNKNOWN DATA FOR THE MODEL, FUTURE DATA; SO IF WE FIT WITH DATA FROM THE FUTURE IS TAKING KNOWLDEGE WE SHOULD NOT KNOW AND GET ADVANTAGE OF IT\n",
        "\n",
        "ct.fit(X_train)   # fit the tranformer to the train data only; we learn from the training and apply it later\n",
        "\n",
        "# Transform training and test data with normalization (MinMaxScaler) and OneHotEncoder\n",
        "\n",
        "X_train_normal = ct.transform(X_train)    # transform both test and train data! Normalizing and one hot encoding!\n",
        "X_test_normal = ct.transform(X_test)"
      ],
      "metadata": {
        "id": "v61EcuSD94mR"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What does our data look like now?\n",
        "X_train.loc[0]    #original data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEfZpO0T_Ffd",
        "outputId": "44ed64d4-6cab-4b76-f2bb-f93dea9880de"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                19\n",
              "sex            female\n",
              "bmi              27.9\n",
              "children            0\n",
              "smoker            yes\n",
              "region      southwest\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_normal[0]  #transformed data for the same row in the data set as above"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yifvkO9d_UuE",
        "outputId": "ddcf480a-2d7a-4229-c00b-6eeb1b4ddfc6"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
              "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_normal  # everything has been correctly transformed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rca0TXGAGt9",
        "outputId": "94b8a1ca-fdbb-458d-b3c7-baa354385cae"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.60869565, 0.10734463, 0.4       , ..., 1.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.63043478, 0.22491256, 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.73913043, 0.23944041, 0.        , ..., 0.        , 1.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.86956522, 0.24791499, 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.41304348, 0.85122411, 0.4       , ..., 0.        , 0.        ,\n",
              "        1.        ],\n",
              "       [0.80434783, 0.37503363, 0.        , ..., 0.        , 0.        ,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How does the shape changes? Additional features are created...(dummy features)...\n",
        "X_train.shape, X_train_normal.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YFBw8ahAQ4W",
        "outputId": "e692306d-07bd-4afe-97be-9f86b649eb5e"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1070, 6), (1070, 11))"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beautiful! Our data has been normalized and one hot encoded.\n",
        "Now let's build a neural network model on it and see how it goes!"
      ],
      "metadata": {
        "id": "fCXf_p3QAlPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a neural network model to fit on our normalized model\n",
        "# Same as before but now with the features normalized!\n",
        "\n",
        "tf.random.set_seed(42)  # for reproducibility\n",
        "\n",
        "# 1. Create a model, reproduce the insurance_model_2 before\n",
        "insurance_model_4 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_4.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(),\n",
        "                          metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "insurance_model_4.fit(X_train_normal, y_train, epochs=100)   # before data was not normalized!\n",
        "\n",
        "# In every experiment we change a small thing at a time, the rest remains the same! In this case we change the data we are using!\n",
        "# Small changes so we can see how that influences the model (keeping the rest constant)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oasxmo6Axiw",
        "outputId": "15dab796-1a6d-4b9a-ba85-2659616a64f5"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 1s 3ms/step - loss: 13342.6494 - mae: 13342.6494\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 13333.4785 - mae: 13333.4785\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13312.0234 - mae: 13312.0234\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 13267.7930 - mae: 13267.7930\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 13189.5830 - mae: 13189.5830\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 13066.4502 - mae: 13066.4502\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12888.1953 - mae: 12888.1953\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 12644.6523 - mae: 12644.6523\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12325.5469 - mae: 12325.5469\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11925.9658 - mae: 11925.9658\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 11454.3350 - mae: 11454.3350\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 10949.8076 - mae: 10949.8076\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10448.9404 - mae: 10448.9404\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9951.6250 - mae: 9951.6250\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9482.7422 - mae: 9482.7422\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 9066.7461 - mae: 9066.7461\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8721.9854 - mae: 8721.9854\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8441.2002 - mae: 8441.2002\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8227.5117 - mae: 8227.5117\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8081.9775 - mae: 8081.9775\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7973.8945 - mae: 7973.8945\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7899.1597 - mae: 7899.1597\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7840.3906 - mae: 7840.3906\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7787.9619 - mae: 7787.9619\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7749.2622 - mae: 7749.2622\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7697.9595 - mae: 7697.9595\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7656.0273 - mae: 7656.0273\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7613.4771 - mae: 7613.4771\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7570.9482 - mae: 7570.9482\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7527.4175 - mae: 7527.4175\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7483.5947 - mae: 7483.5947\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7439.4424 - mae: 7439.4424\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 7395.0552 - mae: 7395.0552\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7346.8120 - mae: 7346.8120\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7300.0488 - mae: 7300.0488\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7249.8452 - mae: 7249.8452\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7199.5308 - mae: 7199.5308\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7148.4814 - mae: 7148.4814\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7093.6660 - mae: 7093.6660\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7038.1797 - mae: 7038.1797\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6981.7393 - mae: 6981.7393\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6922.7847 - mae: 6922.7847\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6860.1724 - mae: 6860.1724\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6793.7979 - mae: 6793.7979\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6726.6201 - mae: 6726.6201\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6657.4683 - mae: 6657.4683\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6586.3086 - mae: 6586.3086\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6507.5063 - mae: 6507.5063\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6428.6021 - mae: 6428.6021\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 6342.7100 - mae: 6342.7100\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6258.0718 - mae: 6258.0718\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6164.7046 - mae: 6164.7046\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6068.6748 - mae: 6068.6748\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5970.0981 - mae: 5970.0981\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 5862.5625 - mae: 5862.5625\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5753.9526 - mae: 5753.9526\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5638.0947 - mae: 5638.0947\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5519.8687 - mae: 5519.8687\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5401.3198 - mae: 5401.3198\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5277.3501 - mae: 5277.3501\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5149.7637 - mae: 5149.7637\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5019.3535 - mae: 5019.3535\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4889.6865 - mae: 4889.6865\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4756.8560 - mae: 4756.8560\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 4629.4370 - mae: 4629.4370\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4503.5991 - mae: 4503.5991\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4392.9922 - mae: 4392.9922\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4284.3862 - mae: 4284.3862\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4182.6182 - mae: 4182.6182\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4089.5725 - mae: 4089.5725\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4003.3901 - mae: 4003.3901\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3929.0093 - mae: 3929.0093\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3866.3110 - mae: 3866.3110\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3813.7144 - mae: 3813.7144\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3773.0317 - mae: 3773.0317\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3744.1995 - mae: 3744.1995\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3719.6870 - mae: 3719.6870\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3702.9109 - mae: 3702.9109\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3691.8792 - mae: 3691.8792\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3682.8350 - mae: 3682.8350\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3676.9763 - mae: 3676.9763\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3673.9495 - mae: 3673.9495\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3667.8452 - mae: 3667.8452\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3664.5757 - mae: 3664.5757\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 3661.8562 - mae: 3661.8562\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 3660.3049 - mae: 3660.3049\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 3657.5134 - mae: 3657.5134\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 3655.2200 - mae: 3655.2200\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3653.8831 - mae: 3653.8831\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 4ms/step - loss: 3652.0195 - mae: 3652.0195\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3648.9990 - mae: 3648.9990\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3648.4463 - mae: 3648.4463\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3646.2297 - mae: 3646.2297\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3644.4377 - mae: 3644.4377\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3645.8772 - mae: 3645.8772\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3642.2573 - mae: 3642.2573\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3640.1187 - mae: 3640.1187\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3638.0647 - mae: 3638.0647\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3637.2053 - mae: 3637.2053\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3636.1707 - mae: 3636.1707\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f652ec23a90>"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate our insurance model trained on normalized data\n",
        "insurance_model_4.evaluate(X_test_normal, y_test)  \n",
        "\n",
        "# Always evaluate in the same type of data it was trained. If its normalized, then normalized; if its not, then not."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IHjzoJvCIjd",
        "outputId": "0757c900-e019-4ec5-a13f-39ed0f33d5da"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3438.7844 - mae: 3438.7844\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3438.784423828125, 3438.784423828125]"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Awesome! Model 2 had a loss of 4924 on the test set!! Much better now just normalizing the data!!\n",
        "# Just normalizing the data, there was a reduction of 30% or so!!! Awesome!!!\n",
        "\n",
        "# NOT ONLY WE CAN CHANGE MODEL HYPERPARAMETERS; COMPILATION; TRAINING...ALSO THE DATA ITSELF!!"
      ],
      "metadata": {
        "id": "4j_WQ5qmCg_C"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MENTALITY, ALWAYS EXPERIMENT! THERE ARE SO MANY THINGS YOU CAN TWEAK, OFTEN THE FIRST RESULTS YOU GET ARE REALLY IMPROVABLE!!"
      ],
      "metadata": {
        "id": "bPipqD-dCuoZ"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the benefits of normalization is a faster convergence time (usually). That means our model gets to a better result faster, in less epochs!"
      ],
      "metadata": {
        "id": "mpnC-67M92tA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### END OF REGRESSION TOPIC!!!"
      ],
      "metadata": {
        "id": "0y7gFxBVDvY1"
      }
    }
  ]
}